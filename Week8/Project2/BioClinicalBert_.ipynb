{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c52b624ca917490ca4752c4ea9cc269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1f6c712cc9a4affbfb55e96b20e5e43",
              "IPY_MODEL_affc3b4182c645c9bef399670e7b75fb",
              "IPY_MODEL_27870000d02b475397d65809aecb1fdf"
            ],
            "layout": "IPY_MODEL_19f565dff3a44fad8360fba1c1ac23fc"
          }
        },
        "a1f6c712cc9a4affbfb55e96b20e5e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e86865c3ee54aa692c42d2b5fee2f74",
            "placeholder": "​",
            "style": "IPY_MODEL_13faf7822a5946b2a333aaba1318994f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "affc3b4182c645c9bef399670e7b75fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e2f91b628ec4229834f5a7e1342d71b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551355c8fbac4c09b8291db19513218a",
            "value": 48
          }
        },
        "27870000d02b475397d65809aecb1fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c19fa13f15d540289f5298e40218f949",
            "placeholder": "​",
            "style": "IPY_MODEL_db7477e8f1a14891a55b622285617fe0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.10kB/s]"
          }
        },
        "19f565dff3a44fad8360fba1c1ac23fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e86865c3ee54aa692c42d2b5fee2f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13faf7822a5946b2a333aaba1318994f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e2f91b628ec4229834f5a7e1342d71b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551355c8fbac4c09b8291db19513218a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c19fa13f15d540289f5298e40218f949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db7477e8f1a14891a55b622285617fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a914ff169e644d338bdaab20acf4045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c755b9ca5e042f39642965e3820d51d",
              "IPY_MODEL_84cb95fbc71c466a8bcfec1406a8e899",
              "IPY_MODEL_4a4ce020fc994fa6af5c77abaa15278a"
            ],
            "layout": "IPY_MODEL_a3cbadcf5990451fa5c45c681bedbe0e"
          }
        },
        "6c755b9ca5e042f39642965e3820d51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d02792721941d5893f45ada2780755",
            "placeholder": "​",
            "style": "IPY_MODEL_6e819f0c5597445b85be7417342b4112",
            "value": "config.json: 100%"
          }
        },
        "84cb95fbc71c466a8bcfec1406a8e899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375ff0a20a62472d8079f0fac03d8451",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20743df710d94d2ea62c955f8662fd61",
            "value": 570
          }
        },
        "4a4ce020fc994fa6af5c77abaa15278a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca2f9561169476a8f4f67fb08c0420d",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa48b789f574d84b33a9b0d0ec95256",
            "value": " 570/570 [00:00&lt;00:00, 33.7kB/s]"
          }
        },
        "a3cbadcf5990451fa5c45c681bedbe0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d02792721941d5893f45ada2780755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e819f0c5597445b85be7417342b4112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375ff0a20a62472d8079f0fac03d8451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20743df710d94d2ea62c955f8662fd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dca2f9561169476a8f4f67fb08c0420d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa48b789f574d84b33a9b0d0ec95256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb31c9532dd74d5bb45aa54508ff5e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d001fbf0ac264f7dafaef76f2729f723",
              "IPY_MODEL_aee11fa8732c4af18269991cedda1ea6",
              "IPY_MODEL_b0d7b79a476f4cec82c757b585ab38e9"
            ],
            "layout": "IPY_MODEL_2835800039ef4f0b9f51b85f73273cb8"
          }
        },
        "d001fbf0ac264f7dafaef76f2729f723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7898a781bcbb47a297349f4c85ff9383",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9b991658be442b97237c07eafe9833",
            "value": "vocab.txt: 100%"
          }
        },
        "aee11fa8732c4af18269991cedda1ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f78f520de3de4bbc8da644ef11d507dc",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57035b4bc3554313b698d23e7ca3f50a",
            "value": 231508
          }
        },
        "b0d7b79a476f4cec82c757b585ab38e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d0e8121ca2445890c1801ec2355e78",
            "placeholder": "​",
            "style": "IPY_MODEL_1f739e51a598444589a8641449b5654f",
            "value": " 232k/232k [00:00&lt;00:00, 6.67MB/s]"
          }
        },
        "2835800039ef4f0b9f51b85f73273cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7898a781bcbb47a297349f4c85ff9383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9b991658be442b97237c07eafe9833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f78f520de3de4bbc8da644ef11d507dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57035b4bc3554313b698d23e7ca3f50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20d0e8121ca2445890c1801ec2355e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f739e51a598444589a8641449b5654f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88dae7a5eff448b8772c7806163b5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d68c36e6a7fc4732b611bb3dacbae7d0",
              "IPY_MODEL_ce109aee1193491590fb8302cc802a25",
              "IPY_MODEL_0469ff9c793845318b962165a0f12e92"
            ],
            "layout": "IPY_MODEL_d6782ecf16014cc4a0d42ae3d9f7c711"
          }
        },
        "d68c36e6a7fc4732b611bb3dacbae7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2688612bc1cb4133bb53a02f92dcc019",
            "placeholder": "​",
            "style": "IPY_MODEL_6a68591d73904b0d95314c5aaea7e278",
            "value": "tokenizer.json: 100%"
          }
        },
        "ce109aee1193491590fb8302cc802a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075d422394bb40c89825734b6b1a8679",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c924b7bb7064091a985c37b1a73de20",
            "value": 466062
          }
        },
        "0469ff9c793845318b962165a0f12e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b4913907fd465ba02f87243cb44193",
            "placeholder": "​",
            "style": "IPY_MODEL_c6c6b83223ad4bcda5b5cd08b781c99b",
            "value": " 466k/466k [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "d6782ecf16014cc4a0d42ae3d9f7c711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2688612bc1cb4133bb53a02f92dcc019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a68591d73904b0d95314c5aaea7e278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "075d422394bb40c89825734b6b1a8679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c924b7bb7064091a985c37b1a73de20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6b4913907fd465ba02f87243cb44193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c6b83223ad4bcda5b5cd08b781c99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20deee98bd31484e8b6fac3ec78c5b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b02f6787ddb4f318d407d05b2ac66d8",
              "IPY_MODEL_e06d85024ec04c8aa1bbf02fd6ee2848",
              "IPY_MODEL_a46c545f1d104edb988999fa98f4388b"
            ],
            "layout": "IPY_MODEL_d3e12beb90ef47319985b8a20898b8cf"
          }
        },
        "7b02f6787ddb4f318d407d05b2ac66d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce57bd2a2094888ad94ab4dc1d230f5",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e9730a057545d09440a09de7e8f431",
            "value": "model.safetensors: 100%"
          }
        },
        "e06d85024ec04c8aa1bbf02fd6ee2848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e6e07337ce411f90bc94393926df8f",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31abc26e0b204d05957adebea8b95529",
            "value": 440449768
          }
        },
        "a46c545f1d104edb988999fa98f4388b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5a5a6400b74bbb8518cbe607a8951d",
            "placeholder": "​",
            "style": "IPY_MODEL_31115ca478d24f84841c9f7965c4d0fb",
            "value": " 440M/440M [00:02&lt;00:00, 236MB/s]"
          }
        },
        "d3e12beb90ef47319985b8a20898b8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ce57bd2a2094888ad94ab4dc1d230f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e9730a057545d09440a09de7e8f431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e6e07337ce411f90bc94393926df8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31abc26e0b204d05957adebea8b95529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c5a5a6400b74bbb8518cbe607a8951d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31115ca478d24f84841c9f7965c4d0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e509ab742348f7b0a113b4e73dafd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_445271f69c5740f9b8e2a87191bc5d0c",
              "IPY_MODEL_40c5a0039c0f4d13a52a4da750bec59b",
              "IPY_MODEL_95a452b8f32045888e79e0085a3b8c84"
            ],
            "layout": "IPY_MODEL_7bc1c8ebf20b493bb5f8f6fd09b493ad"
          }
        },
        "445271f69c5740f9b8e2a87191bc5d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e7189f8ce24b7b95aa0a0abbe4b173",
            "placeholder": "​",
            "style": "IPY_MODEL_25515c943bf440deb837dfa520d91440",
            "value": "config.json: 100%"
          }
        },
        "40c5a0039c0f4d13a52a4da750bec59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4be928bd4104bc59f92519dc3e3aa9d",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6401655a3c464740a269afc29eddc607",
            "value": 385
          }
        },
        "95a452b8f32045888e79e0085a3b8c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1373139508de43198ce668c01d09c0c2",
            "placeholder": "​",
            "style": "IPY_MODEL_736cbbed35c6458a86201697747ac498",
            "value": " 385/385 [00:00&lt;00:00, 7.77kB/s]"
          }
        },
        "7bc1c8ebf20b493bb5f8f6fd09b493ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e7189f8ce24b7b95aa0a0abbe4b173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25515c943bf440deb837dfa520d91440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4be928bd4104bc59f92519dc3e3aa9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6401655a3c464740a269afc29eddc607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1373139508de43198ce668c01d09c0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736cbbed35c6458a86201697747ac498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9397d2fd3613466a9c840cbcda355739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbf12fef7b694132b2ed4f5fb71a1532",
              "IPY_MODEL_51e2a3bd6f4e4e30b9d559cdf8fba7cb",
              "IPY_MODEL_e2d5f529707c498389bc7d6863333d60"
            ],
            "layout": "IPY_MODEL_3123aa3c2e0a46eea90089c8d84b5533"
          }
        },
        "cbf12fef7b694132b2ed4f5fb71a1532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09153210e4cd47c5a2c8d0c547e3e41e",
            "placeholder": "​",
            "style": "IPY_MODEL_e3edcb6cf82041169fc517350904f5c3",
            "value": "vocab.txt: 100%"
          }
        },
        "51e2a3bd6f4e4e30b9d559cdf8fba7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2061d698bd844089a4c041c4b97c768",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5270316d00b41d796b68777a141643d",
            "value": 213450
          }
        },
        "e2d5f529707c498389bc7d6863333d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d38a4b2cd644afa91540542b8a2f965",
            "placeholder": "​",
            "style": "IPY_MODEL_37055a56995e47fc8d96cc4c0908ee8b",
            "value": " 213k/213k [00:00&lt;00:00, 2.79MB/s]"
          }
        },
        "3123aa3c2e0a46eea90089c8d84b5533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09153210e4cd47c5a2c8d0c547e3e41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3edcb6cf82041169fc517350904f5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2061d698bd844089a4c041c4b97c768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5270316d00b41d796b68777a141643d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d38a4b2cd644afa91540542b8a2f965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37055a56995e47fc8d96cc4c0908ee8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "352700c94d174f11a2b96625372aa61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa28cb2849d34f29b7e741fd8854c774",
              "IPY_MODEL_ce15ec86c5f644dd91eaa7024b0accef",
              "IPY_MODEL_99520750ea474fbbb40cff79050d4070"
            ],
            "layout": "IPY_MODEL_730e8eaae1dd4e5aa953af5414766eff"
          }
        },
        "aa28cb2849d34f29b7e741fd8854c774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9def4c2a264874a95f26f7754bd7b5",
            "placeholder": "​",
            "style": "IPY_MODEL_52358db6bb144c1da5db7381a6ff81f0",
            "value": "config.json: 100%"
          }
        },
        "ce15ec86c5f644dd91eaa7024b0accef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe5cb126ac44db39e7fe2822a7c4e85",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52643507b4dd4a68abfce1fe279ff622",
            "value": 385
          }
        },
        "99520750ea474fbbb40cff79050d4070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35df0584cf5428daac7977145829bc2",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d57d41b3314213b8f5c49d382cf121",
            "value": " 385/385 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "730e8eaae1dd4e5aa953af5414766eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9def4c2a264874a95f26f7754bd7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52358db6bb144c1da5db7381a6ff81f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe5cb126ac44db39e7fe2822a7c4e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52643507b4dd4a68abfce1fe279ff622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e35df0584cf5428daac7977145829bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d57d41b3314213b8f5c49d382cf121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73b5aec6c3254836aff7aacb7b8a909f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a709589a1c0a4c5d8a8a2bfb479189e0",
              "IPY_MODEL_0adc4aab0d2d48bd97a1fa1fdc9bc9ad",
              "IPY_MODEL_953f7e45026f425d8c38bed3b23dd8b8"
            ],
            "layout": "IPY_MODEL_8cad5a6953334cc6b0c27e89f5e87b05"
          }
        },
        "a709589a1c0a4c5d8a8a2bfb479189e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b369b2e6b254e28a9c12e70322eca45",
            "placeholder": "​",
            "style": "IPY_MODEL_55df2394ab34409c81531a5be6afc7b0",
            "value": "vocab.txt: 100%"
          }
        },
        "0adc4aab0d2d48bd97a1fa1fdc9bc9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79ca25eeb6b24e8e976c91104f86360f",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7003f8cb1644e10893b9acaa6cc3211",
            "value": 213450
          }
        },
        "953f7e45026f425d8c38bed3b23dd8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3712ed1c8f164c94abb2aad77c62723c",
            "placeholder": "​",
            "style": "IPY_MODEL_aeaa4a1f98b747cfb625ff01f0eda3a4",
            "value": " 213k/213k [00:00&lt;00:00, 5.80MB/s]"
          }
        },
        "8cad5a6953334cc6b0c27e89f5e87b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b369b2e6b254e28a9c12e70322eca45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55df2394ab34409c81531a5be6afc7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79ca25eeb6b24e8e976c91104f86360f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7003f8cb1644e10893b9acaa6cc3211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3712ed1c8f164c94abb2aad77c62723c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeaa4a1f98b747cfb625ff01f0eda3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e5f144e8343415a9187139087fd025e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaa66dab711540e7812b4ea625e1a5a3",
              "IPY_MODEL_05523a28e04b4a1a9c68f570c0a00a2b",
              "IPY_MODEL_8b73f8c4144047b49aedaf5254b566c6"
            ],
            "layout": "IPY_MODEL_5f4e5bc0c558437aa0ccbca33f4b6712"
          }
        },
        "aaa66dab711540e7812b4ea625e1a5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc034183bf0d4850868aef8d6725e224",
            "placeholder": "​",
            "style": "IPY_MODEL_29891a16f6dc490f8d1896c46de77215",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "05523a28e04b4a1a9c68f570c0a00a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aee4a0186374b6596a4b0b93edd9ba8",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57e869be6d6c4de0b600325c493f5b70",
            "value": 435778770
          }
        },
        "8b73f8c4144047b49aedaf5254b566c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f96b3f5dc84b3ab232a007b3f7c42a",
            "placeholder": "​",
            "style": "IPY_MODEL_69aaa4c61c9c4ea5afaed569f185fe1d",
            "value": " 436M/436M [00:03&lt;00:00, 120MB/s]"
          }
        },
        "5f4e5bc0c558437aa0ccbca33f4b6712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc034183bf0d4850868aef8d6725e224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29891a16f6dc490f8d1896c46de77215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aee4a0186374b6596a4b0b93edd9ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e869be6d6c4de0b600325c493f5b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21f96b3f5dc84b3ab232a007b3f7c42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69aaa4c61c9c4ea5afaed569f185fe1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "3c_HcjuRFqU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sepsis is a life-threatening organ dysfunction caused by a dysregulated host response to infection. It occurs when the body’s immune response to an infection becomes uncontrolled, leading to widespread inflammation, tissue damage, and potential organ failure.\n",
        "\n",
        "The Sepsis-3 definition (2016) by the Third International Consensus Definitions for Sepsis and Septic Shock states:\n",
        "\n",
        "\t•\tSepsis: A life-threatening organ dysfunction caused by a dysregulated host response to infection. Organ dysfunction is identified by an increase of 2 or more points in the Sequential Organ Failure Assessment (SOFA) score.\n",
        "\t•\tSeptic Shock: A subset of sepsis characterized by circulatory and cellular/metabolic dysfunction associated with a higher risk of mortality. It is clinically identified by:\n",
        "\t•\tPersistent hypotension requiring vasopressors to maintain a mean arterial pressure (MAP) ≥ 65 mmHg.\n",
        "\t•\tSerum lactate > 2 mmol/L despite adequate fluid resuscitation.\n",
        "\n",
        "Early recognition and prompt treatment with antibiotics, fluid resuscitation, and organ support are crucial to improving outcomes.  Early predictors of sepsis involve a combination of clinical, laboratory, and physiological markers that indicate an escalating inflammatory response and organ dysfunction. Key early indicators include:\n",
        "\n",
        "1. Clinical Signs and Symptoms\n",
        "\n",
        "\t•\tFever or Hypothermia (Temperature >38.3°C or <36°C)\n",
        "\n",
        "\t•\tTachycardia (HR >90 bpm in adults)\n",
        "\n",
        "\t•\tTachypnea or Respiratory Distress (RR >22/min)\n",
        "\n",
        "\t•\tAltered Mental Status (Confusion, disorientation, or lethargy)\n",
        "\n",
        "\t•\tHypotension (Systolic BP <100 mmHg)\n",
        "\n",
        "\t•\tDecreased Urine Output (Oliguria <0.5 mL/kg/h)\n",
        "\n",
        "2. Laboratory Biomarkers\n",
        "\n",
        "\t•\tElevated White Blood Cell Count (WBC) (>12,000/mm³ or <4,000/mm³)\n",
        "\n",
        "\t•\tElevated Procalcitonin (PCT) (>0.5 ng/mL; >2 ng/mL is highly suggestive of sepsis)\n",
        "\n",
        "\t•\tIncreased C-Reactive Protein (CRP) (>100 mg/L)\n",
        "\n",
        "\t•\tElevated Lactate (>2 mmol/L suggests tissue hypoxia; >4 mmol/L is severe)\n",
        "\n",
        "\t•\tCoagulation Abnormalities (INR >1.5, aPTT >60s, or thrombocytopenia <100,000/mm³)\n",
        "\n",
        "3. Scoring Systems for Early Detection\n",
        "\n",
        "\t•\tqSOFA (Quick SOFA) Score (≥2 suggests a higher risk of sepsis)\n",
        "\n",
        "\t•\tRR ≥22/min\n",
        "\n",
        "\t•\tAltered mental status (GCS <15)\n",
        "\n",
        "\t•\tSystolic BP ≤100 mmHg\n",
        "\n",
        "\t•\tSOFA Score (Sequential Organ Failure Assessment; increase by ≥2 points indicates sepsis)\n",
        "\n",
        "\t•\tNEWS (National Early Warning Score) (combines vital signs to detect deterioration)"
      ],
      "metadata": {
        "id": "HibFuUQ-FmQF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-5IlprZbLxm"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage buckets list --project strong-eon-442117-q0 --format=\"value(name)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYJONNV6bXXQ",
        "outputId": "a6d13950-d2b7-44d1-deaa-8130571bd62b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mimic3-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage ls gs://mimic3-dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToV3y3aObbZ8",
        "outputId": "b9d47f9f-567c-4793-efd6-0756ce2f8d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://mimic3-dataset/MIMIC-III/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage ls gs://mimic3-dataset/MIMIC-III/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXH71aTFbfJu",
        "outputId": "1616fca5-06af-4f0a-df7d-a09021b0b906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://mimic3-dataset/MIMIC-III/.DS_Store\n",
            "gs://mimic3-dataset/MIMIC-III/ADMISSIONS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CALLOUT.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CAREGIVERS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CHARTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CPTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DATETIMEEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DIAGNOSES_ICD.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DRGCODES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_CPT.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ICD_DIAGNOSES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ICD_PROCEDURES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ITEMS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_LABITEMS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/ICUSTAYS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/INPUTEVENTS_CV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/INPUTEVENTS_MV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/LABEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/LICENSE.txt\n",
            "gs://mimic3-dataset/MIMIC-III/MICROBIOLOGYEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/NOTEEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/OUTPUTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PATIENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PRESCRIPTIONS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PROCEDUREEVENTS_MV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/README.md\n",
            "gs://mimic3-dataset/MIMIC-III/SERVICES.csv.gz\n",
            "gs://mimic3-dataset/MIMIC-III/SHA256SUMS.txt\n",
            "gs://mimic3-dataset/MIMIC-III/TRANSFERS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/checksum_md5_unzipped.txt\n",
            "gs://mimic3-dataset/MIMIC-III/checksum_md5_zipped.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask  # Install Dask\n",
        "\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQip76b8bk4G",
        "outputId": "81b959ee-b6aa-4b2d-ebf1-9d056440e0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask) (8.6.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing (MIMIC-III)**\n",
        "We need to extract relevant time-series data for patients from MIMIC-III:\n",
        "\n",
        "- Vital Signs (HR, BP, RR, Temp, O2 Sat, Urine Output)\n",
        "- Glascow score (check for deteriration)\n",
        "- Urine output (check for oliguria)\n",
        "- Laboratory Values (WBC, PCT, CRP, Lactate, INR, Platelet Count)\n",
        "- Scoring Systems (qSOFA, SOFA, NEWS)\n",
        "\n",
        "We'll process CHARTEVENTS, LABEVENTS, ICUSTAYS, and ADMISSIONS tables along with NOTES."
      ],
      "metadata": {
        "id": "0Hy9gnONHIJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting & Processing Vital Signs (Heart Rate, BP, Resp Rate, Temp, SpO2, O2 Flow)."
      ],
      "metadata": {
        "id": "klMZDEvl2mKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Correct vital sign ITEMIDs\n",
        "vital_signs = {\n",
        "    220045: \"HeartRate\",\n",
        "    220179: \"SystolicBP\",\n",
        "    220180: \"DiastolicBP\",\n",
        "    220210: \"RespiratoryRate\",\n",
        "    220277: \"SpO2\",\n",
        "    223761: \"Temperature\",\n",
        "    223834: \"O2Flow\",\n",
        "    223835: \"InspiredO2Fraction\"\n",
        "}\n",
        "\n",
        "# Load CHARTEVENTS in chunks using Dask\n",
        "df_vitals = dd.read_csv(\n",
        "    f\"{bucket_path}CHARTEVENTS.csv\",\n",
        "    usecols=[\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"],\n",
        "    dtype={\"ICUSTAY_ID\": \"Int32\", \"CHARTTIME\": \"str\", \"ITEMID\": \"Int32\", \"VALUE\": \"object\"},\n",
        "    assume_missing=True,\n",
        "    blocksize=\"50MB\"\n",
        ")\n",
        "\n",
        "# Convert CHARTTIME to datetime\n",
        "df_vitals[\"CHARTTIME\"] = dd.to_datetime(df_vitals[\"CHARTTIME\"], errors=\"coerce\")\n",
        "\n",
        "# Filter only relevant ITEMIDs\n",
        "df_vitals = df_vitals[df_vitals[\"ITEMID\"].isin(vital_signs.keys())]\n",
        "\n",
        "# Map ITEMID to human-readable labels\n",
        "df_vitals[\"ITEMID\"] = df_vitals[\"ITEMID\"].map(vital_signs, meta=(\"ITEMID\", \"object\"))\n",
        "\n",
        "# Convert VALUE column to numeric safely\n",
        "df_vitals[\"VALUE\"] = df_vitals[\"VALUE\"].apply(pd.to_numeric, errors=\"coerce\", meta=(\"VALUE\", \"float64\"))\n",
        "\n",
        "# Process data in 500K-row batches\n",
        "batch_size = 500_000  # Process 500K rows per batch\n",
        "batch_num = 1\n",
        "\n",
        "# Instead of counting, just process in smaller chunks\n",
        "df_vitals = df_vitals.repartition(npartitions=24)  # ~500K rows per partition\n",
        "\n",
        "for partition in df_vitals.to_delayed():\n",
        "    print(f\"Processing Batch {batch_num}...\")\n",
        "\n",
        "    # Compute only 500K rows (one partition at a time)\n",
        "    df_batch = partition.compute()\n",
        "\n",
        "    # Drop NaNs in VALUE column\n",
        "    df_batch = df_batch.dropna(subset=[\"VALUE\"])\n",
        "\n",
        "    # Aggregate by mean (combine duplicate time entries)\n",
        "    df_batch = df_batch.groupby([\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\"], as_index=False)[\"VALUE\"].mean()\n",
        "\n",
        "    # Pivot table for time-series format\n",
        "    df_batch = df_batch.pivot(index=[\"ICUSTAY_ID\", \"CHARTTIME\"], columns=\"ITEMID\", values=\"VALUE\").reset_index()\n",
        "\n",
        "    # Fill missing values with 0\n",
        "    df_batch.fillna(0, inplace=True)\n",
        "\n",
        "    # Save batch to CSV\n",
        "    batch_filename = f\"/content/vital_signs_batch_{batch_num}.csv\"\n",
        "    df_batch.to_csv(batch_filename, index=False)\n",
        "\n",
        "    print(f\"Saved Batch {batch_num} - {batch_filename}\")\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All batches processed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT8_JOr-boRm",
        "outputId": "ef9a5368-e98b-4408-c976-35157f95d7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Batch 1...\n",
            "Saved Batch 1 - /content/vital_signs_batch_1.csv\n",
            "Processing Batch 2...\n",
            "Saved Batch 2 - /content/vital_signs_batch_2.csv\n",
            "Processing Batch 3...\n",
            "Saved Batch 3 - /content/vital_signs_batch_3.csv\n",
            "Processing Batch 4...\n",
            "Saved Batch 4 - /content/vital_signs_batch_4.csv\n",
            "Processing Batch 5...\n",
            "Saved Batch 5 - /content/vital_signs_batch_5.csv\n",
            "Processing Batch 6...\n",
            "Saved Batch 6 - /content/vital_signs_batch_6.csv\n",
            "Processing Batch 7...\n",
            "Saved Batch 7 - /content/vital_signs_batch_7.csv\n",
            "Processing Batch 8...\n",
            "Saved Batch 8 - /content/vital_signs_batch_8.csv\n",
            "Processing Batch 9...\n",
            "Saved Batch 9 - /content/vital_signs_batch_9.csv\n",
            "Processing Batch 10...\n",
            "Saved Batch 10 - /content/vital_signs_batch_10.csv\n",
            "Processing Batch 11...\n",
            "Saved Batch 11 - /content/vital_signs_batch_11.csv\n",
            "Processing Batch 12...\n",
            "Saved Batch 12 - /content/vital_signs_batch_12.csv\n",
            "Processing Batch 13...\n",
            "Saved Batch 13 - /content/vital_signs_batch_13.csv\n",
            "Processing Batch 14...\n",
            "Saved Batch 14 - /content/vital_signs_batch_14.csv\n",
            "Processing Batch 15...\n",
            "Saved Batch 15 - /content/vital_signs_batch_15.csv\n",
            "Processing Batch 16...\n",
            "Saved Batch 16 - /content/vital_signs_batch_16.csv\n",
            "Processing Batch 17...\n",
            "Saved Batch 17 - /content/vital_signs_batch_17.csv\n",
            "Processing Batch 18...\n",
            "Saved Batch 18 - /content/vital_signs_batch_18.csv\n",
            "Processing Batch 19...\n",
            "Saved Batch 19 - /content/vital_signs_batch_19.csv\n",
            "Processing Batch 20...\n",
            "Saved Batch 20 - /content/vital_signs_batch_20.csv\n",
            "Processing Batch 21...\n",
            "Saved Batch 21 - /content/vital_signs_batch_21.csv\n",
            "Processing Batch 22...\n",
            "Saved Batch 22 - /content/vital_signs_batch_22.csv\n",
            "Processing Batch 23...\n",
            "Saved Batch 23 - /content/vital_signs_batch_23.csv\n",
            "Processing Batch 24...\n",
            "Saved Batch 24 - /content/vital_signs_batch_24.csv\n",
            "All batches processed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract & Process Glasgow Coma Scale (GCS) for Altered Mental Status"
      ],
      "metadata": {
        "id": "KV-xMCD32iS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Glasgow Coma Scale (GCS) ITEMIDs\n",
        "gcs_itemids = {\n",
        "    198: \"GCS_Total\",\n",
        "    454: \"GCS_Verbal\",\n",
        "    184: \"GCS_Motor\",\n",
        "    723: \"GCS_Eye\",\n",
        "    223900: \"GCS_Total\",\n",
        "    220739: \"GCS_Verbal\",\n",
        "    223901: \"GCS_Motor\",\n",
        "    220745: \"GCS_Eye\"\n",
        "}\n",
        "\n",
        "# Load CHARTEVENTS in true chunks using Dask\n",
        "df_gcs = dd.read_csv(\n",
        "    f\"{bucket_path}CHARTEVENTS.csv\",\n",
        "    usecols=[\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"],\n",
        "    dtype={\"ICUSTAY_ID\": \"Int32\", \"CHARTTIME\": \"str\", \"ITEMID\": \"Int32\", \"VALUE\": \"object\"},\n",
        "    assume_missing=True,\n",
        "    blocksize=\"50MB\"\n",
        ")\n",
        "\n",
        "# Convert CHARTTIME to datetime\n",
        "df_gcs[\"CHARTTIME\"] = dd.to_datetime(df_gcs[\"CHARTTIME\"], errors=\"coerce\")\n",
        "\n",
        "# Filter only relevant ITEMIDs (GCS Scores)\n",
        "df_gcs = df_gcs[df_gcs[\"ITEMID\"].isin(gcs_itemids.keys())]\n",
        "\n",
        "# Map ITEMID to human-readable labels\n",
        "df_gcs[\"ITEMID\"] = df_gcs[\"ITEMID\"].map(gcs_itemids, meta=(\"ITEMID\", \"object\"))\n",
        "\n",
        "# Convert VALUE column to numeric safely\n",
        "df_gcs[\"VALUE\"] = df_gcs[\"VALUE\"].apply(pd.to_numeric, errors=\"coerce\", meta=(\"VALUE\", \"float64\"))\n",
        "\n",
        "# Process GCS in smaller batches (500K rows per batch)\n",
        "batch_size = 500_000\n",
        "batch_num = 1\n",
        "\n",
        "df_gcs = df_gcs.repartition(npartitions=24)  # ~500K rows per partition\n",
        "\n",
        "for partition in df_gcs.to_delayed():\n",
        "    print(f\"Processing GCS Batch {batch_num}...\")\n",
        "\n",
        "    # Compute only 500K rows\n",
        "    df_batch = partition.compute()\n",
        "\n",
        "    # Aggregate GCS scores to avoid duplicate entries before pivoting\n",
        "    df_batch = df_batch.groupby([\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\"], as_index=False)[\"VALUE\"].mean()\n",
        "\n",
        "    # Pivot to wide format (one row per ICUSTAY_ID, CHARTTIME)\n",
        "    df_batch = df_batch.pivot(index=[\"ICUSTAY_ID\", \"CHARTTIME\"], columns=\"ITEMID\", values=\"VALUE\").reset_index()\n",
        "\n",
        "    # Ensure all GCS columns exist (fill missing ones with NaN)\n",
        "    for col in [\"GCS_Total\", \"GCS_Verbal\", \"GCS_Motor\", \"GCS_Eye\"]:\n",
        "        if col not in df_batch.columns:\n",
        "            df_batch[col] = float(\"nan\")\n",
        "\n",
        "    # Compute minimum GCS\n",
        "    df_batch[\"GCS_Min\"] = df_batch[[\"GCS_Total\", \"GCS_Verbal\", \"GCS_Motor\", \"GCS_Eye\"]].min(axis=1)\n",
        "\n",
        "    # Flag Altered Mental Status (AMS) if GCS ≤ 12\n",
        "    df_batch[\"Altered_Mental_Status\"] = (df_batch[\"GCS_Min\"] <= 12).astype(int)\n",
        "\n",
        "    # Keep only necessary columns\n",
        "    df_batch = df_batch[[\"ICUSTAY_ID\", \"CHARTTIME\", \"Altered_Mental_Status\"]]\n",
        "\n",
        "    # Save batch to CSV\n",
        "    batch_filename = f\"/content/gcs_batch_{batch_num}.csv\"\n",
        "    df_batch.to_csv(batch_filename, index=False)\n",
        "\n",
        "    print(f\"Saved GCS Batch {batch_num} - {batch_filename}\")\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All GCS batches processed successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzuR4_Mv2Zvw",
        "outputId": "60a65d06-4561-4ba9-ce05-24f2832fc881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing GCS Batch 1...\n",
            "Saved GCS Batch 1 - /content/gcs_batch_1.csv\n",
            "Processing GCS Batch 2...\n",
            "Saved GCS Batch 2 - /content/gcs_batch_2.csv\n",
            "Processing GCS Batch 3...\n",
            "Saved GCS Batch 3 - /content/gcs_batch_3.csv\n",
            "Processing GCS Batch 4...\n",
            "Saved GCS Batch 4 - /content/gcs_batch_4.csv\n",
            "Processing GCS Batch 5...\n",
            "Saved GCS Batch 5 - /content/gcs_batch_5.csv\n",
            "Processing GCS Batch 6...\n",
            "Saved GCS Batch 6 - /content/gcs_batch_6.csv\n",
            "Processing GCS Batch 7...\n",
            "Saved GCS Batch 7 - /content/gcs_batch_7.csv\n",
            "Processing GCS Batch 8...\n",
            "Saved GCS Batch 8 - /content/gcs_batch_8.csv\n",
            "Processing GCS Batch 9...\n",
            "Saved GCS Batch 9 - /content/gcs_batch_9.csv\n",
            "Processing GCS Batch 10...\n",
            "Saved GCS Batch 10 - /content/gcs_batch_10.csv\n",
            "Processing GCS Batch 11...\n",
            "Saved GCS Batch 11 - /content/gcs_batch_11.csv\n",
            "Processing GCS Batch 12...\n",
            "Saved GCS Batch 12 - /content/gcs_batch_12.csv\n",
            "Processing GCS Batch 13...\n",
            "Saved GCS Batch 13 - /content/gcs_batch_13.csv\n",
            "Processing GCS Batch 14...\n",
            "Saved GCS Batch 14 - /content/gcs_batch_14.csv\n",
            "Processing GCS Batch 15...\n",
            "Saved GCS Batch 15 - /content/gcs_batch_15.csv\n",
            "Processing GCS Batch 16...\n",
            "Saved GCS Batch 16 - /content/gcs_batch_16.csv\n",
            "Processing GCS Batch 17...\n",
            "Saved GCS Batch 17 - /content/gcs_batch_17.csv\n",
            "Processing GCS Batch 18...\n",
            "Saved GCS Batch 18 - /content/gcs_batch_18.csv\n",
            "Processing GCS Batch 19...\n",
            "Saved GCS Batch 19 - /content/gcs_batch_19.csv\n",
            "Processing GCS Batch 20...\n",
            "Saved GCS Batch 20 - /content/gcs_batch_20.csv\n",
            "Processing GCS Batch 21...\n",
            "Saved GCS Batch 21 - /content/gcs_batch_21.csv\n",
            "Processing GCS Batch 22...\n",
            "Saved GCS Batch 22 - /content/gcs_batch_22.csv\n",
            "Processing GCS Batch 23...\n",
            "Saved GCS Batch 23 - /content/gcs_batch_23.csv\n",
            "Processing GCS Batch 24...\n",
            "Saved GCS Batch 24 - /content/gcs_batch_24.csv\n",
            "All GCS batches processed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting & Processing urine output (Oliguria)"
      ],
      "metadata": {
        "id": "0zGrbouW4dMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Weight ITEMID (Needs to be verified in D_ITEMS.csv)\n",
        "weight_itemid = {226512}  # Placeholder, verify in D_ITEMS.csv\n",
        "\n",
        "# Load CHARTEVENTS in chunks using Dask\n",
        "df_weight = dd.read_csv(\n",
        "    f\"{bucket_path}CHARTEVENTS.csv\",\n",
        "    usecols=[\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"],\n",
        "    dtype={\"ICUSTAY_ID\": \"Int32\", \"CHARTTIME\": \"str\", \"ITEMID\": \"Int32\", \"VALUE\": \"object\"},\n",
        "    assume_missing=True,\n",
        "    blocksize=\"50MB\"  # Load in small chunks\n",
        ")\n",
        "\n",
        "# Convert CHARTTIME to datetime\n",
        "df_weight[\"CHARTTIME\"] = dd.to_datetime(df_weight[\"CHARTTIME\"], errors=\"coerce\")\n",
        "\n",
        "# Filter only weight ITEMID\n",
        "df_weight = df_weight[df_weight[\"ITEMID\"].isin(weight_itemid)]\n",
        "\n",
        "# Convert VALUE column to numeric safely\n",
        "df_weight[\"VALUE\"] = df_weight[\"VALUE\"].apply(pd.to_numeric, errors=\"coerce\", meta=(\"VALUE\", \"float64\"))\n",
        "\n",
        "# Rename column\n",
        "df_weight = df_weight.rename(columns={\"VALUE\": \"WEIGHT\"})\n",
        "\n",
        "# Keep only necessary columns\n",
        "df_weight = df_weight[[\"ICUSTAY_ID\", \"WEIGHT\"]]\n",
        "\n",
        "# Process in Chunks and Save\n",
        "batch_size = 500_000  # Process 1M rows at a time\n",
        "batch_num = 1\n",
        "df_weight = df_weight.repartition(npartitions=24)  # Split into 24 chunks\n",
        "\n",
        "for partition in df_weight.to_delayed():\n",
        "    print(f\" Processing Weight Batch {batch_num}...\")\n",
        "\n",
        "    # Compute only 1M rows\n",
        "    df_batch = partition.compute()\n",
        "\n",
        "    # Remove NaN values in weight\n",
        "    df_batch = df_batch.dropna()\n",
        "\n",
        "    # Save batch to CSV\n",
        "    batch_filename = f\"/content/weight_batch_{batch_num}.csv\"\n",
        "    df_batch.to_csv(batch_filename, index=False)\n",
        "\n",
        "    print(f\"Saved Weight Batch {batch_num} - {batch_filename}\")\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All Weight Batches Processed Successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDYGGgB24dis",
        "outputId": "f2229a32-9581-4b0c-fdfe-eb2cd405257e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Processing Weight Batch 1...\n",
            "Saved Weight Batch 1 - /content/weight_batch_1.csv\n",
            "🚀 Processing Weight Batch 2...\n",
            "Saved Weight Batch 2 - /content/weight_batch_2.csv\n",
            "🚀 Processing Weight Batch 3...\n",
            "Saved Weight Batch 3 - /content/weight_batch_3.csv\n",
            "🚀 Processing Weight Batch 4...\n",
            "Saved Weight Batch 4 - /content/weight_batch_4.csv\n",
            "🚀 Processing Weight Batch 5...\n",
            "Saved Weight Batch 5 - /content/weight_batch_5.csv\n",
            "🚀 Processing Weight Batch 6...\n",
            "Saved Weight Batch 6 - /content/weight_batch_6.csv\n",
            "🚀 Processing Weight Batch 7...\n",
            "Saved Weight Batch 7 - /content/weight_batch_7.csv\n",
            "🚀 Processing Weight Batch 8...\n",
            "Saved Weight Batch 8 - /content/weight_batch_8.csv\n",
            "🚀 Processing Weight Batch 9...\n",
            "Saved Weight Batch 9 - /content/weight_batch_9.csv\n",
            "🚀 Processing Weight Batch 10...\n",
            "Saved Weight Batch 10 - /content/weight_batch_10.csv\n",
            "🚀 Processing Weight Batch 11...\n",
            "Saved Weight Batch 11 - /content/weight_batch_11.csv\n",
            "🚀 Processing Weight Batch 12...\n",
            "Saved Weight Batch 12 - /content/weight_batch_12.csv\n",
            "🚀 Processing Weight Batch 13...\n",
            "Saved Weight Batch 13 - /content/weight_batch_13.csv\n",
            "🚀 Processing Weight Batch 14...\n",
            "Saved Weight Batch 14 - /content/weight_batch_14.csv\n",
            "🚀 Processing Weight Batch 15...\n",
            "Saved Weight Batch 15 - /content/weight_batch_15.csv\n",
            "🚀 Processing Weight Batch 16...\n",
            "Saved Weight Batch 16 - /content/weight_batch_16.csv\n",
            "🚀 Processing Weight Batch 17...\n",
            "Saved Weight Batch 17 - /content/weight_batch_17.csv\n",
            "🚀 Processing Weight Batch 18...\n",
            "Saved Weight Batch 18 - /content/weight_batch_18.csv\n",
            "🚀 Processing Weight Batch 19...\n",
            "Saved Weight Batch 19 - /content/weight_batch_19.csv\n",
            "🚀 Processing Weight Batch 20...\n",
            "Saved Weight Batch 20 - /content/weight_batch_20.csv\n",
            "🚀 Processing Weight Batch 21...\n",
            "Saved Weight Batch 21 - /content/weight_batch_21.csv\n",
            "🚀 Processing Weight Batch 22...\n",
            "Saved Weight Batch 22 - /content/weight_batch_22.csv\n",
            "🚀 Processing Weight Batch 23...\n",
            "Saved Weight Batch 23 - /content/weight_batch_23.csv\n",
            "🚀 Processing Weight Batch 24...\n",
            "Saved Weight Batch 24 - /content/weight_batch_24.csv\n",
            "All Weight Batches Processed Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert ICUSTAY_ID to integer (fix potential merge issues)\n",
        "df_weight[\"ICUSTAY_ID\"] = pd.to_numeric(df_weight[\"ICUSTAY_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "# Drop any rows where ICUSTAY_ID is NaN (very rare cases)\n",
        "df_weight = df_weight.dropna(subset=[\"ICUSTAY_ID\"])\n",
        "\n",
        "# Print final info after fixing\n",
        "print(\"Weight Data Fixed!\")\n",
        "print(df_weight.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twBUnpCxUlf8",
        "outputId": "45277a0e-7ac2-4111-b2a3-0992f307245f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight Data Fixed!\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22599 entries, 0 to 22598\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ICUSTAY_ID  22599 non-null  Int64  \n",
            " 1   WEIGHT      22599 non-null  float64\n",
            "dtypes: Int64(1), float64(1)\n",
            "memory usage: 375.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_weight[\"ICUSTAY_ID\"] = pd.to_numeric(df_weight[\"ICUSTAY_ID\"], errors=\"coerce\").astype(\"Int64\")"
      ],
      "metadata": {
        "id": "Nh_TxW-lVARr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Step 1: Load Preprocessed Weight Data\n",
        "print(\"Merging all Weight Batches...\")\n",
        "\n",
        "# Find all weight batch files\n",
        "weight_files = sorted(glob.glob(\"/content/weight_batch_*.csv\"))\n",
        "\n",
        "# Merge all weight batches into a single DataFrame\n",
        "df_weight = pd.concat((pd.read_csv(f) for f in weight_files), ignore_index=True)\n",
        "\n",
        "print(\"All Weight Batches Merged!\")\n",
        "print(df_weight.info())\n",
        "\n",
        "# Step 2: Process Urine Output Using Merged Weight Data\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Urine Output ITEMIDs\n",
        "urine_itemids = {\n",
        "    40055, 40056, 40057, 40061, 40065, 43175, 43176, 43177,\n",
        "    43348, 43355, 226559\n",
        "}\n",
        "\n",
        "# Load OUTPUTEVENTS in chunks using Dask\n",
        "df_urine = dd.read_csv(\n",
        "    f\"{bucket_path}OUTPUTEVENTS.csv\",\n",
        "    usecols=[\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"],\n",
        "    dtype={\"ICUSTAY_ID\": \"Int32\", \"CHARTTIME\": \"str\", \"ITEMID\": \"Int32\", \"VALUE\": \"object\"},\n",
        "    assume_missing=True,\n",
        "    blocksize=\"50MB\"\n",
        ")\n",
        "\n",
        "# Convert CHARTTIME to datetime\n",
        "df_urine[\"CHARTTIME\"] = dd.to_datetime(df_urine[\"CHARTTIME\"], errors=\"coerce\")\n",
        "\n",
        "# Filter only relevant ITEMIDs (Urine Output)\n",
        "df_urine = df_urine[df_urine[\"ITEMID\"].isin(urine_itemids)]\n",
        "\n",
        "# Convert VALUE column to numeric safely\n",
        "df_urine[\"VALUE\"] = df_urine[\"VALUE\"].apply(pd.to_numeric, errors=\"coerce\", meta=(\"VALUE\", \"float64\"))\n",
        "\n",
        "# Process urine output batch by batch\n",
        "batch_size = 500_000\n",
        "batch_num = 1\n",
        "df_urine = df_urine.repartition(npartitions=24)  # Split into ~500K-row chunks\n",
        "\n",
        "for partition in df_urine.to_delayed():\n",
        "    print(f\"Processing Urine Output Batch {batch_num}...\")\n",
        "\n",
        "    # Compute only 500K rows\n",
        "    df_batch = partition.compute()\n",
        "\n",
        "    # Aggregate duplicate urine outputs per `ICUSTAY_ID`, `CHARTTIME`\n",
        "    df_batch = df_batch.groupby([\"ICUSTAY_ID\", \"CHARTTIME\"], as_index=False)[\"VALUE\"].sum()\n",
        "\n",
        "    # Merge Urine Output with Patient Weight (Now from merged CSV)\n",
        "    df_batch = df_batch.merge(df_weight, on=\"ICUSTAY_ID\", how=\"left\")\n",
        "\n",
        "    # Assign fillna result properly (instead of inplace=True)\n",
        "    df_batch[\"WEIGHT\"] = df_batch[\"WEIGHT\"].fillna(70)  # Assume 70kg for missing values\n",
        "\n",
        "    # Calculate Urine Output per kg per hour\n",
        "    df_batch[\"Urine_per_kg_per_hour\"] = df_batch[\"VALUE\"] / df_batch[\"WEIGHT\"]\n",
        "\n",
        "    # Flag Oliguria if Urine Output < 0.5 mL/kg/h for >6 hours\n",
        "    df_batch[\"Oliguria\"] = (df_batch[\"Urine_per_kg_per_hour\"] < 0.5).astype(int)\n",
        "\n",
        "    # Keep only necessary columns\n",
        "    df_batch = df_batch[[\"ICUSTAY_ID\", \"CHARTTIME\", \"Oliguria\"]]\n",
        "\n",
        "    # Save batch to CSV\n",
        "    batch_filename = f\"/content/urine_output_batch_{batch_num}.csv\"\n",
        "    df_batch.to_csv(batch_filename, index=False)\n",
        "\n",
        "    print(f\"Saved Urine Output Batch {batch_num} - {batch_filename}\")\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All Urine Output Batches Processed Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm_OP-JwM0ik",
        "outputId": "7d65474c-8beb-44a5-90f9-eb20fc1610eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging all Weight Batches...\n",
            "All Weight Batches Merged!\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22599 entries, 0 to 22598\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ICUSTAY_ID  22599 non-null  object \n",
            " 1   WEIGHT      22599 non-null  float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 353.2+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-f1c905ef6641>:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_weight = pd.concat((pd.read_csv(f) for f in weight_files), ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Urine Output Batch 1...\n",
            "Saved Urine Output Batch 1 - /content/urine_output_batch_1.csv\n",
            "Processing Urine Output Batch 2...\n",
            "Saved Urine Output Batch 2 - /content/urine_output_batch_2.csv\n",
            "Processing Urine Output Batch 3...\n",
            "Saved Urine Output Batch 3 - /content/urine_output_batch_3.csv\n",
            "Processing Urine Output Batch 4...\n",
            "Saved Urine Output Batch 4 - /content/urine_output_batch_4.csv\n",
            "Processing Urine Output Batch 5...\n",
            "Saved Urine Output Batch 5 - /content/urine_output_batch_5.csv\n",
            "Processing Urine Output Batch 6...\n",
            "Saved Urine Output Batch 6 - /content/urine_output_batch_6.csv\n",
            "Processing Urine Output Batch 7...\n",
            "Saved Urine Output Batch 7 - /content/urine_output_batch_7.csv\n",
            "Processing Urine Output Batch 8...\n",
            "Saved Urine Output Batch 8 - /content/urine_output_batch_8.csv\n",
            "Processing Urine Output Batch 9...\n",
            "Saved Urine Output Batch 9 - /content/urine_output_batch_9.csv\n",
            "Processing Urine Output Batch 10...\n",
            "Saved Urine Output Batch 10 - /content/urine_output_batch_10.csv\n",
            "Processing Urine Output Batch 11...\n",
            "Saved Urine Output Batch 11 - /content/urine_output_batch_11.csv\n",
            "Processing Urine Output Batch 12...\n",
            "Saved Urine Output Batch 12 - /content/urine_output_batch_12.csv\n",
            "Processing Urine Output Batch 13...\n",
            "Saved Urine Output Batch 13 - /content/urine_output_batch_13.csv\n",
            "Processing Urine Output Batch 14...\n",
            "Saved Urine Output Batch 14 - /content/urine_output_batch_14.csv\n",
            "Processing Urine Output Batch 15...\n",
            "Saved Urine Output Batch 15 - /content/urine_output_batch_15.csv\n",
            "Processing Urine Output Batch 16...\n",
            "Saved Urine Output Batch 16 - /content/urine_output_batch_16.csv\n",
            "Processing Urine Output Batch 17...\n",
            "Saved Urine Output Batch 17 - /content/urine_output_batch_17.csv\n",
            "Processing Urine Output Batch 18...\n",
            "Saved Urine Output Batch 18 - /content/urine_output_batch_18.csv\n",
            "Processing Urine Output Batch 19...\n",
            "Saved Urine Output Batch 19 - /content/urine_output_batch_19.csv\n",
            "Processing Urine Output Batch 20...\n",
            "Saved Urine Output Batch 20 - /content/urine_output_batch_20.csv\n",
            "Processing Urine Output Batch 21...\n",
            "Saved Urine Output Batch 21 - /content/urine_output_batch_21.csv\n",
            "Processing Urine Output Batch 22...\n",
            "Saved Urine Output Batch 22 - /content/urine_output_batch_22.csv\n",
            "Processing Urine Output Batch 23...\n",
            "Saved Urine Output Batch 23 - /content/urine_output_batch_23.csv\n",
            "Processing Urine Output Batch 24...\n",
            "Saved Urine Output Batch 24 - /content/urine_output_batch_24.csv\n",
            "All Urine Output Batches Processed Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting & Processing sepsis-related laboratory biomarkers"
      ],
      "metadata": {
        "id": "dxoRQqinCGj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Relevant Lab ITEMIDs\n",
        "lab_itemids = {\n",
        "    51300: \"WBC\",          # White Blood Cell Count\n",
        "    50862: \"CRP\",          # C-Reactive Protein\n",
        "    50960: \"Lactate\",      # Lactate\n",
        "    51237: \"INR\",          # International Normalized Ratio\n",
        "    51275: \"aPTT\",         # Activated Partial Thromboplastin Time\n",
        "    51265: \"Platelets\",    # Platelet Count\n",
        "    50810: \"PCT\",          # Procalcitonin\n",
        "    50813: \"ScvO2\"         # Central Venous Oxygen Saturation\n",
        "}\n",
        "\n",
        "# Load LABEVENTS in chunks using Dask (Fix: Use SUBJECT_ID, HADM_ID)\n",
        "df_labs = dd.read_csv(\n",
        "    f\"{bucket_path}LABEVENTS.csv\",\n",
        "    usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"CHARTTIME\", \"ITEMID\", \"VALUE\"],\n",
        "    dtype={\"SUBJECT_ID\": \"Int32\", \"HADM_ID\": \"Int32\", \"CHARTTIME\": \"str\", \"ITEMID\": \"Int32\", \"VALUE\": \"object\"},\n",
        "    assume_missing=True,\n",
        "    blocksize=\"50MB\"\n",
        ")\n",
        "\n",
        "# Convert CHARTTIME to datetime\n",
        "df_labs[\"CHARTTIME\"] = dd.to_datetime(df_labs[\"CHARTTIME\"], errors=\"coerce\")\n",
        "\n",
        "# Filter only relevant ITEMIDs (Lab results)\n",
        "df_labs = df_labs[df_labs[\"ITEMID\"].isin(lab_itemids.keys())]\n",
        "\n",
        "# Map ITEMID to human-readable labels\n",
        "df_labs[\"ITEMID\"] = df_labs[\"ITEMID\"].map(lab_itemids, meta=(\"ITEMID\", \"object\"))\n",
        "\n",
        "# Convert VALUE column to numeric safely\n",
        "df_labs[\"VALUE\"] = df_labs[\"VALUE\"].apply(pd.to_numeric, errors=\"coerce\", meta=(\"VALUE\", \"float64\"))\n",
        "\n",
        "# Load ICU stay mapping to get ICUSTAY_ID\n",
        "df_icustays = dd.read_csv(\n",
        "    f\"{bucket_path}ICUSTAYS.csv\",\n",
        "    usecols=[\"SUBJECT_ID\", \"HADM_ID\", \"ICUSTAY_ID\"],\n",
        "    dtype={\"SUBJECT_ID\": \"Int32\", \"HADM_ID\": \"Int32\", \"ICUSTAY_ID\": \"Int32\"},\n",
        "    assume_missing=True\n",
        ")\n",
        "\n",
        "# Merge LABEVENTS with ICUSTAYS to get `ICUSTAY_ID`\n",
        "df_labs = df_labs.merge(df_icustays, on=[\"SUBJECT_ID\", \"HADM_ID\"], how=\"left\")\n",
        "\n",
        "# Process Labs in 500K-row chunks\n",
        "batch_size = 500_000\n",
        "batch_num = 1\n",
        "\n",
        "df_labs = df_labs.repartition(npartitions=24)  # ~500K rows per partition\n",
        "\n",
        "for partition in df_labs.to_delayed():\n",
        "    print(f\"Processing Lab Batch {batch_num}...\")\n",
        "\n",
        "    # Compute only 500K rows\n",
        "    df_batch = partition.compute()\n",
        "\n",
        "    # Drop rows without an `ICUSTAY_ID` (focus on ICU patients)\n",
        "    df_batch = df_batch.dropna(subset=[\"ICUSTAY_ID\"])\n",
        "\n",
        "    # Aggregate duplicate lab values by mean\n",
        "    df_batch = df_batch.groupby([\"ICUSTAY_ID\", \"CHARTTIME\", \"ITEMID\"], as_index=False)[\"VALUE\"].mean()\n",
        "\n",
        "    # Pivot table for time-series format\n",
        "    df_batch = df_batch.pivot(index=[\"ICUSTAY_ID\", \"CHARTTIME\"], columns=\"ITEMID\", values=\"VALUE\").reset_index()\n",
        "\n",
        "    # Save batch to CSV\n",
        "    batch_filename = f\"/content/lab_results_batch_{batch_num}.csv\"\n",
        "    df_batch.to_csv(batch_filename, index=False)\n",
        "\n",
        "    print(f\"Saved Lab Batch {batch_num} - {batch_filename}\")\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All Lab Batches Processed Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oEHmOHGCHCG",
        "outputId": "92f45394-a0fc-4a65-f10c-2a0fbd9a8e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Lab Batch 1...\n",
            "Saved Lab Batch 1 - /content/lab_results_batch_1.csv\n",
            "Processing Lab Batch 2...\n",
            "Saved Lab Batch 2 - /content/lab_results_batch_2.csv\n",
            "Processing Lab Batch 3...\n",
            "Saved Lab Batch 3 - /content/lab_results_batch_3.csv\n",
            "Processing Lab Batch 4...\n",
            "Saved Lab Batch 4 - /content/lab_results_batch_4.csv\n",
            "Processing Lab Batch 5...\n",
            "Saved Lab Batch 5 - /content/lab_results_batch_5.csv\n",
            "Processing Lab Batch 6...\n",
            "Saved Lab Batch 6 - /content/lab_results_batch_6.csv\n",
            "Processing Lab Batch 7...\n",
            "Saved Lab Batch 7 - /content/lab_results_batch_7.csv\n",
            "Processing Lab Batch 8...\n",
            "Saved Lab Batch 8 - /content/lab_results_batch_8.csv\n",
            "Processing Lab Batch 9...\n",
            "Saved Lab Batch 9 - /content/lab_results_batch_9.csv\n",
            "Processing Lab Batch 10...\n",
            "Saved Lab Batch 10 - /content/lab_results_batch_10.csv\n",
            "Processing Lab Batch 11...\n",
            "Saved Lab Batch 11 - /content/lab_results_batch_11.csv\n",
            "Processing Lab Batch 12...\n",
            "Saved Lab Batch 12 - /content/lab_results_batch_12.csv\n",
            "Processing Lab Batch 13...\n",
            "Saved Lab Batch 13 - /content/lab_results_batch_13.csv\n",
            "Processing Lab Batch 14...\n",
            "Saved Lab Batch 14 - /content/lab_results_batch_14.csv\n",
            "Processing Lab Batch 15...\n",
            "Saved Lab Batch 15 - /content/lab_results_batch_15.csv\n",
            "Processing Lab Batch 16...\n",
            "Saved Lab Batch 16 - /content/lab_results_batch_16.csv\n",
            "Processing Lab Batch 17...\n",
            "Saved Lab Batch 17 - /content/lab_results_batch_17.csv\n",
            "Processing Lab Batch 18...\n",
            "Saved Lab Batch 18 - /content/lab_results_batch_18.csv\n",
            "Processing Lab Batch 19...\n",
            "Saved Lab Batch 19 - /content/lab_results_batch_19.csv\n",
            "Processing Lab Batch 20...\n",
            "Saved Lab Batch 20 - /content/lab_results_batch_20.csv\n",
            "Processing Lab Batch 21...\n",
            "Saved Lab Batch 21 - /content/lab_results_batch_21.csv\n",
            "Processing Lab Batch 22...\n",
            "Saved Lab Batch 22 - /content/lab_results_batch_22.csv\n",
            "Processing Lab Batch 23...\n",
            "Saved Lab Batch 23 - /content/lab_results_batch_23.csv\n",
            "Processing Lab Batch 24...\n",
            "Saved Lab Batch 24 - /content/lab_results_batch_24.csv\n",
            "All Lab Batches Processed Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Sepsis related notes in clinical NOTES"
      ],
      "metadata": {
        "id": "s45SP0cWXfnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Choice: BioClinicalBERT\n",
        "Since general BERT models struggle with medical terminology and BioClinicalBERT understands sepsis, AMS, and ICU-related language.\n",
        "Instead of using a general BERT model, we will use BioClinicalBERT, a BERT model fine-tuned on clinical notes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-6EKA_A7FE6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNQVH11qFF8K",
        "outputId": "c950151a-c873-48c2-a642-6dd738ae5a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m837.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed datasets-3.4.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available!\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU is NOT available! Running on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So6OJRaGYXFK",
        "outputId": "289a1062-09c3-48ef-b529-e57f67468412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is NOT available! Running on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Force CPU mode\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "# Load Transformer Model on CPU\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"  # Example: Change this based on your task\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Move model to CPU\n",
        "model.to(device)\n",
        "\n",
        "# Example input\n",
        "text = \"Sepsis is a severe response to infection.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "print(\"Model successfully ran on CPU!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "c52b624ca917490ca4752c4ea9cc269e",
            "a1f6c712cc9a4affbfb55e96b20e5e43",
            "affc3b4182c645c9bef399670e7b75fb",
            "27870000d02b475397d65809aecb1fdf",
            "19f565dff3a44fad8360fba1c1ac23fc",
            "3e86865c3ee54aa692c42d2b5fee2f74",
            "13faf7822a5946b2a333aaba1318994f",
            "8e2f91b628ec4229834f5a7e1342d71b",
            "551355c8fbac4c09b8291db19513218a",
            "c19fa13f15d540289f5298e40218f949",
            "db7477e8f1a14891a55b622285617fe0",
            "a914ff169e644d338bdaab20acf4045e",
            "6c755b9ca5e042f39642965e3820d51d",
            "84cb95fbc71c466a8bcfec1406a8e899",
            "4a4ce020fc994fa6af5c77abaa15278a",
            "a3cbadcf5990451fa5c45c681bedbe0e",
            "d9d02792721941d5893f45ada2780755",
            "6e819f0c5597445b85be7417342b4112",
            "375ff0a20a62472d8079f0fac03d8451",
            "20743df710d94d2ea62c955f8662fd61",
            "dca2f9561169476a8f4f67fb08c0420d",
            "6fa48b789f574d84b33a9b0d0ec95256",
            "fb31c9532dd74d5bb45aa54508ff5e1b",
            "d001fbf0ac264f7dafaef76f2729f723",
            "aee11fa8732c4af18269991cedda1ea6",
            "b0d7b79a476f4cec82c757b585ab38e9",
            "2835800039ef4f0b9f51b85f73273cb8",
            "7898a781bcbb47a297349f4c85ff9383",
            "4f9b991658be442b97237c07eafe9833",
            "f78f520de3de4bbc8da644ef11d507dc",
            "57035b4bc3554313b698d23e7ca3f50a",
            "20d0e8121ca2445890c1801ec2355e78",
            "1f739e51a598444589a8641449b5654f",
            "f88dae7a5eff448b8772c7806163b5e6",
            "d68c36e6a7fc4732b611bb3dacbae7d0",
            "ce109aee1193491590fb8302cc802a25",
            "0469ff9c793845318b962165a0f12e92",
            "d6782ecf16014cc4a0d42ae3d9f7c711",
            "2688612bc1cb4133bb53a02f92dcc019",
            "6a68591d73904b0d95314c5aaea7e278",
            "075d422394bb40c89825734b6b1a8679",
            "6c924b7bb7064091a985c37b1a73de20",
            "a6b4913907fd465ba02f87243cb44193",
            "c6c6b83223ad4bcda5b5cd08b781c99b",
            "20deee98bd31484e8b6fac3ec78c5b16",
            "7b02f6787ddb4f318d407d05b2ac66d8",
            "e06d85024ec04c8aa1bbf02fd6ee2848",
            "a46c545f1d104edb988999fa98f4388b",
            "d3e12beb90ef47319985b8a20898b8cf",
            "3ce57bd2a2094888ad94ab4dc1d230f5",
            "a7e9730a057545d09440a09de7e8f431",
            "e8e6e07337ce411f90bc94393926df8f",
            "31abc26e0b204d05957adebea8b95529",
            "0c5a5a6400b74bbb8518cbe607a8951d",
            "31115ca478d24f84841c9f7965c4d0fb"
          ]
        },
        "id": "9XqrKk6vY1Uc",
        "outputId": "4980b53b-93bb-47a9-fd2e-f8281aba53bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c52b624ca917490ca4752c4ea9cc269e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a914ff169e644d338bdaab20acf4045e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb31c9532dd74d5bb45aa54508ff5e1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f88dae7a5eff448b8772c7806163b5e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20deee98bd31484e8b6fac3ec78c5b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully ran on CPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are extracting free-text clinical notes from the NOTEEVENTS.csv file in MIMIC-III. This file contains unstructured textual data written by medical professionals.\n",
        "\n",
        "Relevant Text Categories for Sepsis Detection: We filtered specific categories of notes that might contain sepsis-related information:\n",
        "\n",
        "Category\tPurpose in Sepsis Detection\n",
        "- Nursing\tCaptures real-time patient monitoring, vital signs, fluid balance, and early deterioration signs.\n",
        "- Physician\tProvides clinical reasoning, suspected infections, antibiotic decisions, and differential diagnoses.\n",
        "Progress\tTracks changes in patient condition, response to treatment, and worsening infections.\n",
        "- Discharge Summary\tSummarizes the entire hospital stay, including final diagnosis and interventions taken.\n",
        "\n",
        "In these notes, we are checking for sepsis-related phrases and patterns, such as:\n",
        "\n",
        "1. Clinical Signs of Sepsis\n",
        "\"Fever of 38.5°C\", \"Tachycardia (HR 120 bpm)\", \"Hypotensive, BP 85/50\", \"Altered mental status, confused\", \"Urine output < 30 mL/hr (oliguria)\"\n",
        "2. Infection & Suspected Sepsis: \"Suspected sepsis\", \"Septic shock\", \"Bacteremia\", \"Severe pneumonia\", \"Gram-negative bacteremia\", \"Infection source unclear, empiric antibiotics started\"\n",
        "3. Lab and Biomarkers Indicating Sepsis: \"Elevated lactate > 2.5 mmol/L\", \"Elevated WBC count > 15,000\", \"High CRP 120 mg/L\", \"INR 1.7, aPTT 65s, suspecting DIC\", \"Procalcitonin 3.5 ng/mL, highly suspicious of bacterial sepsis\"\n",
        "4. Hemodynamic & Organ Dysfunction: \"Started norepinephrine due to persistent hypotension\", \"MAP below 65 despite fluid resuscitation\", \"Started mechanical ventilation, worsening ARDS\", \"AKI developing, creatinine rising\""
      ],
      "metadata": {
        "id": "TrlcduNDbDdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/\"\n",
        "\n",
        "# Load only the first few rows to check available columns\n",
        "df_check = dd.read_csv(f\"{bucket_path}NOTEEVENTS.csv\", blocksize=\"10MB\")\n",
        "print(df_check.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI3E3qLZbw9n",
        "outputId": "632502d5-20c5-48c0-a4a7-d462db01e241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME',\n",
            "       'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'TEXT'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import gc  # Garbage collection to free memory\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Force CPU mode (to avoid GPU issues)\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "# Load Pretrained Clinical BERT Model\n",
        "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
        "model.to(device)  # Move model to CPU\n",
        "\n",
        "print(\"Bio_ClinicalBERT is now running on CPU!\")\n",
        "\n",
        "# Google Cloud Storage Path\n",
        "bucket_path = \"gs://mimic3-dataset/MIMIC-III/NOTEEVENTS.csv\"\n",
        "\n",
        "# Step 1: Verify Available Column Names (Load a small sample)\n",
        "print(\"🔍 Checking column names in NOTEEVENTS.csv...\")\n",
        "df_test = pd.read_csv(bucket_path, nrows=5, encoding=\"utf-8\", low_memory=False)\n",
        "df_test.columns = df_test.columns.str.strip()  #  Remove extra spaces in column names\n",
        "available_columns = df_test.columns.tolist()\n",
        "print(f\"✔ Found columns: {available_columns}\")\n",
        "\n",
        "# Step 2: Select correct columns\n",
        "time_col = \"CHARTTIME\" if \"CHARTTIME\" in available_columns else \"CHARTDATE\"\n",
        "expected_columns = [\"HADM_ID\", time_col, \"CATEGORY\", \"TEXT\"]\n",
        "selected_columns = [col for col in expected_columns if col in available_columns]\n",
        "\n",
        "if not selected_columns:\n",
        "    raise ValueError(\"No matching columns found in the dataset!\")\n",
        "\n",
        "print(f\"✔ Using columns: {selected_columns}\")\n",
        "\n",
        "# Step 3: Process Data in Smaller Chunks\n",
        "print(\"Processing NOTEEVENTS in small chunks to avoid memory crash...\")\n",
        "chunk_size = 25_000  # Reduce batch size (prevents RAM overuse)\n",
        "batch_num = 1\n",
        "processed_files = []\n",
        "\n",
        "# Read in chunks and process on the fly\n",
        "for chunk in pd.read_csv(bucket_path, usecols=selected_columns, chunksize=chunk_size, encoding=\"utf-8\", low_memory=False):\n",
        "    print(f\"Processing Notes Batch {batch_num}...\")\n",
        "\n",
        "    # Drop rows with missing text\n",
        "    chunk = chunk.dropna(subset=[\"TEXT\"])\n",
        "\n",
        "    # Keep only relevant note categories\n",
        "    relevant_categories = [\"Nursing\", \"Physician\", \"Progress\", \"Discharge summary\"]\n",
        "    chunk = chunk[chunk[\"CATEGORY\"].isin(relevant_categories)]\n",
        "\n",
        "    # Convert CHARTTIME to datetime\n",
        "    chunk[time_col] = pd.to_datetime(chunk[time_col], errors=\"coerce\")  # Convert safely\n",
        "    chunk[time_col] = chunk[time_col].astype(\"datetime64[ns]\")  # Explicitly set dtype\n",
        "\n",
        "    # Skip tokenization for now (just clean and save data)\n",
        "    batch_filename = f\"/content/clean_notes_batch_{batch_num}.parquet\"\n",
        "    chunk.to_parquet(batch_filename, index=False)\n",
        "    processed_files.append(batch_filename)\n",
        "\n",
        "    print(f\"Saved Clean Notes Batch {batch_num} - {batch_filename}\")\n",
        "\n",
        "    # Free memory manually\n",
        "    del chunk\n",
        "    gc.collect()  # Force garbage collection to free RAM\n",
        "\n",
        "    batch_num += 1\n",
        "\n",
        "print(\"All Clean Notes Batches Processed Successfully!\")\n",
        "print(f\"Processed files: {processed_files}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuIl2Xguruy1",
        "outputId": "09d4ddd1-367d-4987-97a4-bc59ec14a7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bio_ClinicalBERT is now running on CPU!\n",
            "🔍 Checking column names in NOTEEVENTS.csv...\n",
            "✔ Found columns: ['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME', 'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'TEXT']\n",
            "✔ Using columns: ['HADM_ID', 'CHARTTIME', 'CATEGORY', 'TEXT']\n",
            "Processing NOTEEVENTS in small chunks to avoid memory crash...\n",
            "Processing Notes Batch 1...\n",
            "Saved Clean Notes Batch 1 - /content/clean_notes_batch_1.parquet\n",
            "Processing Notes Batch 2...\n",
            "Saved Clean Notes Batch 2 - /content/clean_notes_batch_2.parquet\n",
            "Processing Notes Batch 3...\n",
            "Saved Clean Notes Batch 3 - /content/clean_notes_batch_3.parquet\n",
            "Processing Notes Batch 4...\n",
            "Saved Clean Notes Batch 4 - /content/clean_notes_batch_4.parquet\n",
            "Processing Notes Batch 5...\n",
            "Saved Clean Notes Batch 5 - /content/clean_notes_batch_5.parquet\n",
            "Processing Notes Batch 6...\n",
            "Saved Clean Notes Batch 6 - /content/clean_notes_batch_6.parquet\n",
            "Processing Notes Batch 7...\n",
            "Saved Clean Notes Batch 7 - /content/clean_notes_batch_7.parquet\n",
            "Processing Notes Batch 8...\n",
            "Saved Clean Notes Batch 8 - /content/clean_notes_batch_8.parquet\n",
            "Processing Notes Batch 9...\n",
            "Saved Clean Notes Batch 9 - /content/clean_notes_batch_9.parquet\n",
            "Processing Notes Batch 10...\n",
            "Saved Clean Notes Batch 10 - /content/clean_notes_batch_10.parquet\n",
            "Processing Notes Batch 11...\n",
            "Saved Clean Notes Batch 11 - /content/clean_notes_batch_11.parquet\n",
            "Processing Notes Batch 12...\n",
            "Saved Clean Notes Batch 12 - /content/clean_notes_batch_12.parquet\n",
            "Processing Notes Batch 13...\n",
            "Saved Clean Notes Batch 13 - /content/clean_notes_batch_13.parquet\n",
            "Processing Notes Batch 14...\n",
            "Saved Clean Notes Batch 14 - /content/clean_notes_batch_14.parquet\n",
            "Processing Notes Batch 15...\n",
            "Saved Clean Notes Batch 15 - /content/clean_notes_batch_15.parquet\n",
            "Processing Notes Batch 16...\n",
            "Saved Clean Notes Batch 16 - /content/clean_notes_batch_16.parquet\n",
            "Processing Notes Batch 17...\n",
            "Saved Clean Notes Batch 17 - /content/clean_notes_batch_17.parquet\n",
            "Processing Notes Batch 18...\n",
            "Saved Clean Notes Batch 18 - /content/clean_notes_batch_18.parquet\n",
            "Processing Notes Batch 19...\n",
            "Saved Clean Notes Batch 19 - /content/clean_notes_batch_19.parquet\n",
            "Processing Notes Batch 20...\n",
            "Saved Clean Notes Batch 20 - /content/clean_notes_batch_20.parquet\n",
            "Processing Notes Batch 21...\n",
            "Saved Clean Notes Batch 21 - /content/clean_notes_batch_21.parquet\n",
            "Processing Notes Batch 22...\n",
            "Saved Clean Notes Batch 22 - /content/clean_notes_batch_22.parquet\n",
            "Processing Notes Batch 23...\n",
            "Saved Clean Notes Batch 23 - /content/clean_notes_batch_23.parquet\n",
            "Processing Notes Batch 24...\n",
            "Saved Clean Notes Batch 24 - /content/clean_notes_batch_24.parquet\n",
            "Processing Notes Batch 25...\n",
            "Saved Clean Notes Batch 25 - /content/clean_notes_batch_25.parquet\n",
            "Processing Notes Batch 26...\n",
            "Saved Clean Notes Batch 26 - /content/clean_notes_batch_26.parquet\n",
            "Processing Notes Batch 27...\n",
            "Saved Clean Notes Batch 27 - /content/clean_notes_batch_27.parquet\n",
            "Processing Notes Batch 28...\n",
            "Saved Clean Notes Batch 28 - /content/clean_notes_batch_28.parquet\n",
            "Processing Notes Batch 29...\n",
            "Saved Clean Notes Batch 29 - /content/clean_notes_batch_29.parquet\n",
            "Processing Notes Batch 30...\n",
            "Saved Clean Notes Batch 30 - /content/clean_notes_batch_30.parquet\n",
            "Processing Notes Batch 31...\n",
            "Saved Clean Notes Batch 31 - /content/clean_notes_batch_31.parquet\n",
            "Processing Notes Batch 32...\n",
            "Saved Clean Notes Batch 32 - /content/clean_notes_batch_32.parquet\n",
            "Processing Notes Batch 33...\n",
            "Saved Clean Notes Batch 33 - /content/clean_notes_batch_33.parquet\n",
            "Processing Notes Batch 34...\n",
            "Saved Clean Notes Batch 34 - /content/clean_notes_batch_34.parquet\n",
            "Processing Notes Batch 35...\n",
            "Saved Clean Notes Batch 35 - /content/clean_notes_batch_35.parquet\n",
            "Processing Notes Batch 36...\n",
            "Saved Clean Notes Batch 36 - /content/clean_notes_batch_36.parquet\n",
            "Processing Notes Batch 37...\n",
            "Saved Clean Notes Batch 37 - /content/clean_notes_batch_37.parquet\n",
            "Processing Notes Batch 38...\n",
            "Saved Clean Notes Batch 38 - /content/clean_notes_batch_38.parquet\n",
            "Processing Notes Batch 39...\n",
            "Saved Clean Notes Batch 39 - /content/clean_notes_batch_39.parquet\n",
            "Processing Notes Batch 40...\n",
            "Saved Clean Notes Batch 40 - /content/clean_notes_batch_40.parquet\n",
            "Processing Notes Batch 41...\n",
            "Saved Clean Notes Batch 41 - /content/clean_notes_batch_41.parquet\n",
            "Processing Notes Batch 42...\n",
            "Saved Clean Notes Batch 42 - /content/clean_notes_batch_42.parquet\n",
            "Processing Notes Batch 43...\n",
            "Saved Clean Notes Batch 43 - /content/clean_notes_batch_43.parquet\n",
            "Processing Notes Batch 44...\n",
            "Saved Clean Notes Batch 44 - /content/clean_notes_batch_44.parquet\n",
            "Processing Notes Batch 45...\n",
            "Saved Clean Notes Batch 45 - /content/clean_notes_batch_45.parquet\n",
            "Processing Notes Batch 46...\n",
            "Saved Clean Notes Batch 46 - /content/clean_notes_batch_46.parquet\n",
            "Processing Notes Batch 47...\n",
            "Saved Clean Notes Batch 47 - /content/clean_notes_batch_47.parquet\n",
            "Processing Notes Batch 48...\n",
            "Saved Clean Notes Batch 48 - /content/clean_notes_batch_48.parquet\n",
            "Processing Notes Batch 49...\n",
            "Saved Clean Notes Batch 49 - /content/clean_notes_batch_49.parquet\n",
            "Processing Notes Batch 50...\n",
            "Saved Clean Notes Batch 50 - /content/clean_notes_batch_50.parquet\n",
            "Processing Notes Batch 51...\n",
            "Saved Clean Notes Batch 51 - /content/clean_notes_batch_51.parquet\n",
            "Processing Notes Batch 52...\n",
            "Saved Clean Notes Batch 52 - /content/clean_notes_batch_52.parquet\n",
            "Processing Notes Batch 53...\n",
            "Saved Clean Notes Batch 53 - /content/clean_notes_batch_53.parquet\n",
            "Processing Notes Batch 54...\n",
            "Saved Clean Notes Batch 54 - /content/clean_notes_batch_54.parquet\n",
            "Processing Notes Batch 55...\n",
            "Saved Clean Notes Batch 55 - /content/clean_notes_batch_55.parquet\n",
            "Processing Notes Batch 56...\n",
            "Saved Clean Notes Batch 56 - /content/clean_notes_batch_56.parquet\n",
            "Processing Notes Batch 57...\n",
            "Saved Clean Notes Batch 57 - /content/clean_notes_batch_57.parquet\n",
            "Processing Notes Batch 58...\n",
            "Saved Clean Notes Batch 58 - /content/clean_notes_batch_58.parquet\n",
            "Processing Notes Batch 59...\n",
            "Saved Clean Notes Batch 59 - /content/clean_notes_batch_59.parquet\n",
            "Processing Notes Batch 60...\n",
            "Saved Clean Notes Batch 60 - /content/clean_notes_batch_60.parquet\n",
            "Processing Notes Batch 61...\n",
            "Saved Clean Notes Batch 61 - /content/clean_notes_batch_61.parquet\n",
            "Processing Notes Batch 62...\n",
            "Saved Clean Notes Batch 62 - /content/clean_notes_batch_62.parquet\n",
            "Processing Notes Batch 63...\n",
            "Saved Clean Notes Batch 63 - /content/clean_notes_batch_63.parquet\n",
            "Processing Notes Batch 64...\n",
            "Saved Clean Notes Batch 64 - /content/clean_notes_batch_64.parquet\n",
            "Processing Notes Batch 65...\n",
            "Saved Clean Notes Batch 65 - /content/clean_notes_batch_65.parquet\n",
            "Processing Notes Batch 66...\n",
            "Saved Clean Notes Batch 66 - /content/clean_notes_batch_66.parquet\n",
            "Processing Notes Batch 67...\n",
            "Saved Clean Notes Batch 67 - /content/clean_notes_batch_67.parquet\n",
            "Processing Notes Batch 68...\n",
            "Saved Clean Notes Batch 68 - /content/clean_notes_batch_68.parquet\n",
            "Processing Notes Batch 69...\n",
            "Saved Clean Notes Batch 69 - /content/clean_notes_batch_69.parquet\n",
            "Processing Notes Batch 70...\n",
            "Saved Clean Notes Batch 70 - /content/clean_notes_batch_70.parquet\n",
            "Processing Notes Batch 71...\n",
            "Saved Clean Notes Batch 71 - /content/clean_notes_batch_71.parquet\n",
            "Processing Notes Batch 72...\n",
            "Saved Clean Notes Batch 72 - /content/clean_notes_batch_72.parquet\n",
            "Processing Notes Batch 73...\n",
            "Saved Clean Notes Batch 73 - /content/clean_notes_batch_73.parquet\n",
            "Processing Notes Batch 74...\n",
            "Saved Clean Notes Batch 74 - /content/clean_notes_batch_74.parquet\n",
            "Processing Notes Batch 75...\n",
            "Saved Clean Notes Batch 75 - /content/clean_notes_batch_75.parquet\n",
            "Processing Notes Batch 76...\n",
            "Saved Clean Notes Batch 76 - /content/clean_notes_batch_76.parquet\n",
            "Processing Notes Batch 77...\n",
            "Saved Clean Notes Batch 77 - /content/clean_notes_batch_77.parquet\n",
            "Processing Notes Batch 78...\n",
            "Saved Clean Notes Batch 78 - /content/clean_notes_batch_78.parquet\n",
            "Processing Notes Batch 79...\n",
            "Saved Clean Notes Batch 79 - /content/clean_notes_batch_79.parquet\n",
            "Processing Notes Batch 80...\n",
            "Saved Clean Notes Batch 80 - /content/clean_notes_batch_80.parquet\n",
            "Processing Notes Batch 81...\n",
            "Saved Clean Notes Batch 81 - /content/clean_notes_batch_81.parquet\n",
            "Processing Notes Batch 82...\n",
            "Saved Clean Notes Batch 82 - /content/clean_notes_batch_82.parquet\n",
            "Processing Notes Batch 83...\n",
            "Saved Clean Notes Batch 83 - /content/clean_notes_batch_83.parquet\n",
            "Processing Notes Batch 84...\n",
            "Saved Clean Notes Batch 84 - /content/clean_notes_batch_84.parquet\n",
            "All Clean Notes Batches Processed Successfully!\n",
            "Processed files: ['/content/clean_notes_batch_1.parquet', '/content/clean_notes_batch_2.parquet', '/content/clean_notes_batch_3.parquet', '/content/clean_notes_batch_4.parquet', '/content/clean_notes_batch_5.parquet', '/content/clean_notes_batch_6.parquet', '/content/clean_notes_batch_7.parquet', '/content/clean_notes_batch_8.parquet', '/content/clean_notes_batch_9.parquet', '/content/clean_notes_batch_10.parquet', '/content/clean_notes_batch_11.parquet', '/content/clean_notes_batch_12.parquet', '/content/clean_notes_batch_13.parquet', '/content/clean_notes_batch_14.parquet', '/content/clean_notes_batch_15.parquet', '/content/clean_notes_batch_16.parquet', '/content/clean_notes_batch_17.parquet', '/content/clean_notes_batch_18.parquet', '/content/clean_notes_batch_19.parquet', '/content/clean_notes_batch_20.parquet', '/content/clean_notes_batch_21.parquet', '/content/clean_notes_batch_22.parquet', '/content/clean_notes_batch_23.parquet', '/content/clean_notes_batch_24.parquet', '/content/clean_notes_batch_25.parquet', '/content/clean_notes_batch_26.parquet', '/content/clean_notes_batch_27.parquet', '/content/clean_notes_batch_28.parquet', '/content/clean_notes_batch_29.parquet', '/content/clean_notes_batch_30.parquet', '/content/clean_notes_batch_31.parquet', '/content/clean_notes_batch_32.parquet', '/content/clean_notes_batch_33.parquet', '/content/clean_notes_batch_34.parquet', '/content/clean_notes_batch_35.parquet', '/content/clean_notes_batch_36.parquet', '/content/clean_notes_batch_37.parquet', '/content/clean_notes_batch_38.parquet', '/content/clean_notes_batch_39.parquet', '/content/clean_notes_batch_40.parquet', '/content/clean_notes_batch_41.parquet', '/content/clean_notes_batch_42.parquet', '/content/clean_notes_batch_43.parquet', '/content/clean_notes_batch_44.parquet', '/content/clean_notes_batch_45.parquet', '/content/clean_notes_batch_46.parquet', '/content/clean_notes_batch_47.parquet', '/content/clean_notes_batch_48.parquet', '/content/clean_notes_batch_49.parquet', '/content/clean_notes_batch_50.parquet', '/content/clean_notes_batch_51.parquet', '/content/clean_notes_batch_52.parquet', '/content/clean_notes_batch_53.parquet', '/content/clean_notes_batch_54.parquet', '/content/clean_notes_batch_55.parquet', '/content/clean_notes_batch_56.parquet', '/content/clean_notes_batch_57.parquet', '/content/clean_notes_batch_58.parquet', '/content/clean_notes_batch_59.parquet', '/content/clean_notes_batch_60.parquet', '/content/clean_notes_batch_61.parquet', '/content/clean_notes_batch_62.parquet', '/content/clean_notes_batch_63.parquet', '/content/clean_notes_batch_64.parquet', '/content/clean_notes_batch_65.parquet', '/content/clean_notes_batch_66.parquet', '/content/clean_notes_batch_67.parquet', '/content/clean_notes_batch_68.parquet', '/content/clean_notes_batch_69.parquet', '/content/clean_notes_batch_70.parquet', '/content/clean_notes_batch_71.parquet', '/content/clean_notes_batch_72.parquet', '/content/clean_notes_batch_73.parquet', '/content/clean_notes_batch_74.parquet', '/content/clean_notes_batch_75.parquet', '/content/clean_notes_batch_76.parquet', '/content/clean_notes_batch_77.parquet', '/content/clean_notes_batch_78.parquet', '/content/clean_notes_batch_79.parquet', '/content/clean_notes_batch_80.parquet', '/content/clean_notes_batch_81.parquet', '/content/clean_notes_batch_82.parquet', '/content/clean_notes_batch_83.parquet', '/content/clean_notes_batch_84.parquet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Get all saved Parquet files\n",
        "parquet_files = sorted(glob.glob(\"/content/clean_notes_batch_*.parquet\"))\n",
        "\n",
        "# Load and concatenate all files into a single DataFrame\n",
        "df_notes_final = pd.concat([pd.read_parquet(f) for f in parquet_files], ignore_index=True)\n",
        "\n",
        "# Save final merged file\n",
        "df_notes_final.to_parquet(\"/content/clean_notes_final.parquet\", index=False)\n",
        "\n",
        "print(\"Merged all notes into clean_notes_final.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY5fo-2qwsQb",
        "outputId": "04e2ff47-3f7f-423e-f7e2-2fc06b043c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged all notes into clean_notes_final.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "File clean_notes_final.parquet saved in Google Cloud Storage with the rest of the files. Saved here for ease of access"
      ],
      "metadata": {
        "id": "OHpufmz9fNa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "4vSVKBFjfZNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage buckets list --project strong-eon-442117-q0 --format=\"value(name)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9gFuwMSfns1",
        "outputId": "588c6949-cff8-46c2-9dd1-9654d685ff71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mimic3-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage ls gs://mimic3-dataset/MIMIC-III/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJqdopk8fs5P",
        "outputId": "b038b4ba-22e6-4661-8fc8-85f6000a92e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gs://mimic3-dataset/MIMIC-III/.DS_Store\n",
            "gs://mimic3-dataset/MIMIC-III/ADMISSIONS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CALLOUT.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CAREGIVERS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CHARTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/CPTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DATETIMEEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DIAGNOSES_ICD.csv\n",
            "gs://mimic3-dataset/MIMIC-III/DRGCODES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_CPT.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ICD_DIAGNOSES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ICD_PROCEDURES.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_ITEMS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/D_LABITEMS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/ICUSTAYS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/INPUTEVENTS_CV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/INPUTEVENTS_MV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/LABEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/LICENSE.txt\n",
            "gs://mimic3-dataset/MIMIC-III/MICROBIOLOGYEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/NOTEEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/OUTPUTEVENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PATIENTS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PRESCRIPTIONS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/PROCEDUREEVENTS_MV.csv\n",
            "gs://mimic3-dataset/MIMIC-III/README.md\n",
            "gs://mimic3-dataset/MIMIC-III/SERVICES.csv.gz\n",
            "gs://mimic3-dataset/MIMIC-III/SHA256SUMS.txt\n",
            "gs://mimic3-dataset/MIMIC-III/TRANSFERS.csv\n",
            "gs://mimic3-dataset/MIMIC-III/checksum_md5_unzipped.txt\n",
            "gs://mimic3-dataset/MIMIC-III/checksum_md5_zipped.txt\n",
            "gs://mimic3-dataset/MIMIC-III/clean_notes_final.parquet\n",
            "gs://mimic3-dataset/MIMIC-III/final_cleaned_dataset.csv\n",
            "gs://mimic3-dataset/MIMIC-III/final_dataset_with_diagnoses.csv\n",
            "gs://mimic3-dataset/MIMIC-III/final_dataset_with_diagnoses.parquet\n",
            "gs://mimic3-dataset/MIMIC-III/final_dataset_with_diagnoses_flattened.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the clinical notes\n",
        "notes_df = pd.read_parquet('gs://mimic3-dataset/MIMIC-III/clean_notes_final.parquet')\n",
        "\n",
        "# Display basic info\n",
        "print(notes_df.info())\n",
        "print(notes_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bkHajm2fzb7",
        "outputId": "d4a37060-8902-4c23-e830-694242bd6b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 283208 entries, 0 to 283207\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype         \n",
            "---  ------     --------------   -----         \n",
            " 0   HADM_ID    280410 non-null  float64       \n",
            " 1   CHARTTIME  222172 non-null  datetime64[ns]\n",
            " 2   CATEGORY   283208 non-null  object        \n",
            " 3   TEXT       283208 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(1), object(2)\n",
            "memory usage: 8.6+ MB\n",
            "None\n",
            "    HADM_ID CHARTTIME           CATEGORY  \\\n",
            "0  167853.0       NaT  Discharge summary   \n",
            "1  107527.0       NaT  Discharge summary   \n",
            "2  167118.0       NaT  Discharge summary   \n",
            "3  196489.0       NaT  Discharge summary   \n",
            "4  135453.0       NaT  Discharge summary   \n",
            "\n",
            "                                                TEXT  \n",
            "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
            "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
            "2  Admission Date:  [**2119-5-4**]              D...  \n",
            "3  Admission Date:  [**2124-7-21**]              ...  \n",
            "4  Admission Date:  [**2162-3-3**]              D...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load clinical notes dataset\n",
        "notes_df = pd.read_parquet(\"gs://mimic3-dataset/MIMIC-III/clean_notes_final.parquet\")\n",
        "\n",
        "# Load sepsis diagnosis data\n",
        "diagnoses_df = pd.read_csv(\"gs://mimic3-dataset/MIMIC-III/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "# Display basic info\n",
        "print(\"Clinical Notes Dataset:\")\n",
        "print(notes_df.info())\n",
        "\n",
        "print(\"\\nSepsis Diagnoses Dataset:\")\n",
        "print(diagnoses_df.info())\n",
        "\n",
        "# Check column names\n",
        "print(\"\\nClinical Notes Columns:\", notes_df.columns.tolist())\n",
        "print(\"\\nDiagnosis Columns:\", diagnoses_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Vg_6u5gSVG",
        "outputId": "9e1501a4-154c-4341-e1e1-aa01af2825d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical Notes Dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 283208 entries, 0 to 283207\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype         \n",
            "---  ------     --------------   -----         \n",
            " 0   HADM_ID    280410 non-null  float64       \n",
            " 1   CHARTTIME  222172 non-null  datetime64[ns]\n",
            " 2   CATEGORY   283208 non-null  object        \n",
            " 3   TEXT       283208 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(1), object(2)\n",
            "memory usage: 8.6+ MB\n",
            "None\n",
            "\n",
            "Sepsis Diagnoses Dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 651047 entries, 0 to 651046\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   ROW_ID      651047 non-null  int64  \n",
            " 1   SUBJECT_ID  651047 non-null  int64  \n",
            " 2   HADM_ID     651047 non-null  int64  \n",
            " 3   SEQ_NUM     651000 non-null  float64\n",
            " 4   ICD9_CODE   651000 non-null  object \n",
            "dtypes: float64(1), int64(3), object(1)\n",
            "memory usage: 24.8+ MB\n",
            "None\n",
            "\n",
            "Clinical Notes Columns: ['HADM_ID', 'CHARTTIME', 'CATEGORY', 'TEXT']\n",
            "\n",
            "Diagnosis Columns: ['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sepsis-related ICD-9/10 codes (expand this list if needed)\n",
        "sepsis_codes = [\n",
        "    \"038\", \"038.0\", \"038.1\", \"038.10\", \"038.11\", \"038.12\", \"038.19\",  # Bacteremia-related\n",
        "    \"995.91\", \"995.92\", \"785.52\",  # Severe sepsis, septic shock\n",
        "    \"A41\", \"A41.0\", \"A41.1\", \"A41.2\", \"A41.3\", \"A41.4\", \"A41.5\", \"A41.8\", \"A41.9\"  # ICD-10 Sepsis codes\n",
        "]\n",
        "\n",
        "# Convert ICD9 codes to strings for matching\n",
        "diagnoses_df[\"ICD9_CODE\"] = diagnoses_df[\"ICD9_CODE\"].astype(str)\n",
        "\n",
        "# Identify sepsis cases\n",
        "diagnoses_df[\"sepsis\"] = diagnoses_df[\"ICD9_CODE\"].str.startswith(tuple(sepsis_codes))\n",
        "\n",
        "# Keep only sepsis-positive admissions\n",
        "sepsis_df = diagnoses_df[diagnoses_df[\"sepsis\"] == True][[\"HADM_ID\", \"sepsis\"]]\n",
        "\n",
        "# Remove duplicates (some patients may have multiple sepsis diagnoses)\n",
        "sepsis_df = sepsis_df.drop_duplicates(subset=\"HADM_ID\")\n",
        "\n",
        "# Show the number of sepsis cases\n",
        "print(f\"Total Sepsis Cases Identified: {sepsis_df['HADM_ID'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBUFh1pRg6Q1",
        "outputId": "46d3e73a-b886-4f1f-ceab-8007a519d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sepsis Cases Identified: 6265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert HADM_ID to integers for proper merging\n",
        "notes_df[\"HADM_ID\"] = notes_df[\"HADM_ID\"].fillna(0).astype(\"Int64\")\n",
        "sepsis_df[\"HADM_ID\"] = sepsis_df[\"HADM_ID\"].astype(\"Int64\")\n",
        "\n",
        "# Merge clinical notes with sepsis labels\n",
        "merged_df = notes_df.merge(sepsis_df, on=\"HADM_ID\", how=\"left\")\n",
        "\n",
        "# Fill NaN values (patients without sepsis) with 0\n",
        "merged_df[\"sepsis\"] = merged_df[\"sepsis\"].fillna(False).astype(int)\n",
        "\n",
        "# Check final counts\n",
        "print(merged_df[\"sepsis\"].value_counts())\n",
        "print(merged_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiLZlkUBhFZR",
        "outputId": "e42104a8-b6a7-4829-b5ea-e36ee6ba0a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepsis\n",
            "0    218925\n",
            "1     64283\n",
            "Name: count, dtype: int64\n",
            "   HADM_ID CHARTTIME           CATEGORY  \\\n",
            "0   167853       NaT  Discharge summary   \n",
            "1   107527       NaT  Discharge summary   \n",
            "2   167118       NaT  Discharge summary   \n",
            "3   196489       NaT  Discharge summary   \n",
            "4   135453       NaT  Discharge summary   \n",
            "\n",
            "                                                TEXT  sepsis  \n",
            "0  Admission Date:  [**2151-7-16**]       Dischar...       0  \n",
            "1  Admission Date:  [**2118-6-2**]       Discharg...       0  \n",
            "2  Admission Date:  [**2119-5-4**]              D...       0  \n",
            "3  Admission Date:  [**2124-7-21**]              ...       0  \n",
            "4  Admission Date:  [**2162-3-3**]              D...       0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5adb8f38cc5c>:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  merged_df[\"sepsis\"] = merged_df[\"sepsis\"].fillna(False).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final dataset as Parquet\n",
        "merged_df.to_parquet(\"/content/sepsis_notes.parquet\", index=False)\n",
        "\n",
        "print(\"Successfully saved `sepsis_notes.parquet` with labeled sepsis cases!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34wSafKPhL8X",
        "outputId": "04edc3c1-e5c0-4841-e84e-a35be19cebe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved `sepsis_notes.parquet` with labeled sepsis cases!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess & Tokenize Text for BioClinicalBERT**"
      ],
      "metadata": {
        "id": "vrGjqOVMhqaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data & Install Necessary Libraries: First, we need to load the dataset and install Hugging Face's Transformers"
      ],
      "metadata": {
        "id": "U9fhqljJiApe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the saved dataset\n",
        "df = pd.read_parquet(\"/content/sepsis_notes.parquet\")\n",
        "\n",
        "# Install transformers if not installed\n",
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "2E9DXQ8ah0Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Clinical Notes: Transformers require clean, normalized text, so we should:\n",
        "1. Convert text to lowercase\n",
        "2. Remove special characters & extra spaces\n",
        "3. Remove dates, numeric tokens, and non-relevant symbols"
      ],
      "metadata": {
        "id": "4sqKMmG7iI4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BioClinicalBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Remove bracketed text (e.g., anonymized dates)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean_text\"] = df[\"TEXT\"].apply(preprocess_text)\n",
        "\n",
        "# Display sample cleaned text\n",
        "print(df[[\"TEXT\", \"clean_text\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404,
          "referenced_widgets": [
            "79e509ab742348f7b0a113b4e73dafd4",
            "445271f69c5740f9b8e2a87191bc5d0c",
            "40c5a0039c0f4d13a52a4da750bec59b",
            "95a452b8f32045888e79e0085a3b8c84",
            "7bc1c8ebf20b493bb5f8f6fd09b493ad",
            "b7e7189f8ce24b7b95aa0a0abbe4b173",
            "25515c943bf440deb837dfa520d91440",
            "a4be928bd4104bc59f92519dc3e3aa9d",
            "6401655a3c464740a269afc29eddc607",
            "1373139508de43198ce668c01d09c0c2",
            "736cbbed35c6458a86201697747ac498",
            "9397d2fd3613466a9c840cbcda355739",
            "cbf12fef7b694132b2ed4f5fb71a1532",
            "51e2a3bd6f4e4e30b9d559cdf8fba7cb",
            "e2d5f529707c498389bc7d6863333d60",
            "3123aa3c2e0a46eea90089c8d84b5533",
            "09153210e4cd47c5a2c8d0c547e3e41e",
            "e3edcb6cf82041169fc517350904f5c3",
            "d2061d698bd844089a4c041c4b97c768",
            "a5270316d00b41d796b68777a141643d",
            "4d38a4b2cd644afa91540542b8a2f965",
            "37055a56995e47fc8d96cc4c0908ee8b"
          ]
        },
        "id": "8GUntSzdiRn_",
        "outputId": "f351a804-bbf5-4201-a01a-dc1ffe132350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79e509ab742348f7b0a113b4e73dafd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9397d2fd3613466a9c840cbcda355739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                TEXT  \\\n",
            "0  Admission Date:  [**2151-7-16**]       Dischar...   \n",
            "1  Admission Date:  [**2118-6-2**]       Discharg...   \n",
            "2  Admission Date:  [**2119-5-4**]              D...   \n",
            "3  Admission Date:  [**2124-7-21**]              ...   \n",
            "4  Admission Date:  [**2162-3-3**]              D...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  admission date: discharge date: service: adden...  \n",
            "1  admission date: discharge date: date of birth:...  \n",
            "2  admission date: discharge date: service: cardi...  \n",
            "3  admission date: discharge date: service: medic...  \n",
            "4  admission date: discharge date: date of birth:...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize Text for BioClinicalBERT: we convert the text into numerical tokens using BioClinicalBERT\n",
        "Due to insufficient RAMs, the approach will be Instead of applying .apply() to the entire dataset at once, we process it in small chunks using Dask; and then to tokenize in mini-batches"
      ],
      "metadata": {
        "id": "lMoDrlopianN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask -q\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Load dataset using Dask for memory efficiency\n",
        "df = dd.read_parquet(\"/content/sepsis_notes.parquet\")\n",
        "\n",
        "# Convert Dask dataframe to Pandas in small chunks\n",
        "df_pandas = df.compute()  # If crashing, reduce sample size (e.g., df.sample(frac=0.5))"
      ],
      "metadata": {
        "id": "dxaual6rieyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "import pandas as pd\n",
        "df_pandas = pd.read_parquet(\"/content/sepsis_notes.parquet\")\n",
        "\n",
        "# Print available columns\n",
        "print(\"Available columns:\", df_pandas.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Men8H8L7lLev",
        "outputId": "57900a7d-a4cf-4493-e25c-0f564d91e765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['HADM_ID', 'CHARTTIME', 'CATEGORY', 'TEXT', 'sepsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_parquet(\"/content/sepsis_notes.parquet\")\n",
        "\n",
        "# Function to clean text\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Remove anonymized dates\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "df[\"clean_text\"] = df[\"TEXT\"].apply(preprocess_text)\n",
        "\n",
        "# Save updated dataframe\n",
        "df.to_parquet(\"/content/sepsis_notes_cleaned.parquet\", index=False)\n",
        "\n",
        "print(\"Successfully added `clean_text` and saved to `sepsis_notes_cleaned.parquet`!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w0wbh_wleJe",
        "outputId": "80c9de75-1d6d-401a-ef08-aa7ead70e3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added `clean_text` and saved to `sepsis_notes_cleaned.parquet`!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload dataset\n",
        "df_check = pd.read_parquet(\"/content/sepsis_notes_cleaned.parquet\")\n",
        "\n",
        "# Print columns\n",
        "print(\"Available columns:\", df_check.columns.tolist())\n",
        "\n",
        "# Show sample\n",
        "print(df_check[[\"TEXT\", \"clean_text\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1wtTiFQl-rV",
        "outputId": "be2c0c1c-1b0d-4ed2-f4ac-51819b084634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['HADM_ID', 'CHARTTIME', 'CATEGORY', 'TEXT', 'sepsis', 'clean_text']\n",
            "                                                TEXT  \\\n",
            "0  Admission Date:  [**2151-7-16**]       Dischar...   \n",
            "1  Admission Date:  [**2118-6-2**]       Discharg...   \n",
            "2  Admission Date:  [**2119-5-4**]              D...   \n",
            "3  Admission Date:  [**2124-7-21**]              ...   \n",
            "4  Admission Date:  [**2162-3-3**]              D...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  admission date: discharge date: service: adden...  \n",
            "1  admission date: discharge date: date of birth:...  \n",
            "2  admission date: discharge date: service: cardi...  \n",
            "3  admission date: discharge date: service: medic...  \n",
            "4  admission date: discharge date: date of birth:...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Get total and available memory\n",
        "total_mem = psutil.virtual_memory().total / (1024**3)  # Convert to GB\n",
        "available_mem = psutil.virtual_memory().available / (1024**3)  # Convert to GB\n",
        "\n",
        "print(f\"Total RAM: {total_mem:.2f} GB\")\n",
        "print(f\"Available RAM: {available_mem:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6ciyG5DvjL-",
        "outputId": "5825eec8-468e-4837-a79b-2789fd741795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 12.67 GB\n",
            "Available RAM: 10.85 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import gc\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import gc\n",
        "import os\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "\n",
        "# Load dataset\n",
        "df_path = \"/content/sepsis_notes_cleaned.parquet\"\n",
        "df = pd.read_parquet(df_path, columns=[\"HADM_ID\", \"clean_text\", \"sepsis\"])\n",
        "\n",
        "# Check available RAM\n",
        "available_mem = psutil.virtual_memory().available / (1024**3)\n",
        "print(f\"Available RAM: {available_mem:.2f} GB\")\n",
        "\n",
        "# Set batch size dynamically (reduce if crashing)\n",
        "batch_size = 1000\n",
        "print(f\"Using batch size: {batch_size}\")\n",
        "\n",
        "# Define output path\n",
        "output_path = \"/content/sepsis_notes_tokenized.parquet\"\n",
        "\n",
        "# Function for batch tokenization\n",
        "def batch_tokenization(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Initialize Parquet Writer\n",
        "parquet_writer = None\n",
        "\n",
        "# Process text in batches & append to Parquet manually\n",
        "for i in range(0, len(df), batch_size):\n",
        "    print(f\"Processing batch {i} - {min(i+batch_size, len(df))}...\")\n",
        "\n",
        "    batch_texts = df[\"clean_text\"].iloc[i:i+batch_size].tolist()\n",
        "\n",
        "    # Tokenize batch\n",
        "    tokens = batch_tokenization(batch_texts)\n",
        "\n",
        "    # Convert to dictionary format\n",
        "    batch_output = pd.DataFrame({\n",
        "        \"HADM_ID\": df[\"HADM_ID\"].iloc[i:i+batch_size].values,\n",
        "        \"input_ids\": [tokens[\"input_ids\"][j].tolist() for j in range(len(batch_texts))],\n",
        "        \"attention_mask\": [tokens[\"attention_mask\"][j].tolist() for j in range(len(batch_texts))],\n",
        "        \"sepsis\": df[\"sepsis\"].iloc[i:i+batch_size].values\n",
        "    })\n",
        "\n",
        "    # Convert Pandas DataFrame to PyArrow Table\n",
        "    table = pa.Table.from_pandas(batch_output)\n",
        "\n",
        "    # If first batch, create Parquet file, otherwise append\n",
        "    if parquet_writer is None:\n",
        "        parquet_writer = pq.ParquetWriter(output_path, table.schema, compression=\"snappy\")\n",
        "\n",
        "    parquet_writer.write_table(table)\n",
        "\n",
        "    # Free memory manually after each batch\n",
        "    del tokens, batch_texts, batch_output, table\n",
        "    torch.cuda.empty_cache()  # Clear GPU memory\n",
        "    gc.collect()  # Clear CPU memory\n",
        "\n",
        "# Close Parquet writer after all batches are processed\n",
        "if parquet_writer:\n",
        "    parquet_writer.close()\n",
        "\n",
        "print(\"Successfully tokenized dataset and saved it in batches!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlsMrn4Ivvus",
        "outputId": "93c1a600-a055-4c9b-be9f-04ff8075ed90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available RAM: 7.37 GB\n",
            "Using batch size: 1000\n",
            "Processing batch 0 - 1000...\n",
            "Processing batch 1000 - 2000...\n",
            "Processing batch 2000 - 3000...\n",
            "Processing batch 3000 - 4000...\n",
            "Processing batch 4000 - 5000...\n",
            "Processing batch 5000 - 6000...\n",
            "Processing batch 6000 - 7000...\n",
            "Processing batch 7000 - 8000...\n",
            "Processing batch 8000 - 9000...\n",
            "Processing batch 9000 - 10000...\n",
            "Processing batch 10000 - 11000...\n",
            "Processing batch 11000 - 12000...\n",
            "Processing batch 12000 - 13000...\n",
            "Processing batch 13000 - 14000...\n",
            "Processing batch 14000 - 15000...\n",
            "Processing batch 15000 - 16000...\n",
            "Processing batch 16000 - 17000...\n",
            "Processing batch 17000 - 18000...\n",
            "Processing batch 18000 - 19000...\n",
            "Processing batch 19000 - 20000...\n",
            "Processing batch 20000 - 21000...\n",
            "Processing batch 21000 - 22000...\n",
            "Processing batch 22000 - 23000...\n",
            "Processing batch 23000 - 24000...\n",
            "Processing batch 24000 - 25000...\n",
            "Processing batch 25000 - 26000...\n",
            "Processing batch 26000 - 27000...\n",
            "Processing batch 27000 - 28000...\n",
            "Processing batch 28000 - 29000...\n",
            "Processing batch 29000 - 30000...\n",
            "Processing batch 30000 - 31000...\n",
            "Processing batch 31000 - 32000...\n",
            "Processing batch 32000 - 33000...\n",
            "Processing batch 33000 - 34000...\n",
            "Processing batch 34000 - 35000...\n",
            "Processing batch 35000 - 36000...\n",
            "Processing batch 36000 - 37000...\n",
            "Processing batch 37000 - 38000...\n",
            "Processing batch 38000 - 39000...\n",
            "Processing batch 39000 - 40000...\n",
            "Processing batch 40000 - 41000...\n",
            "Processing batch 41000 - 42000...\n",
            "Processing batch 42000 - 43000...\n",
            "Processing batch 43000 - 44000...\n",
            "Processing batch 44000 - 45000...\n",
            "Processing batch 45000 - 46000...\n",
            "Processing batch 46000 - 47000...\n",
            "Processing batch 47000 - 48000...\n",
            "Processing batch 48000 - 49000...\n",
            "Processing batch 49000 - 50000...\n",
            "Processing batch 50000 - 51000...\n",
            "Processing batch 51000 - 52000...\n",
            "Processing batch 52000 - 53000...\n",
            "Processing batch 53000 - 54000...\n",
            "Processing batch 54000 - 55000...\n",
            "Processing batch 55000 - 56000...\n",
            "Processing batch 56000 - 57000...\n",
            "Processing batch 57000 - 58000...\n",
            "Processing batch 58000 - 59000...\n",
            "Processing batch 59000 - 60000...\n",
            "Processing batch 60000 - 61000...\n",
            "Processing batch 61000 - 62000...\n",
            "Processing batch 62000 - 63000...\n",
            "Processing batch 63000 - 64000...\n",
            "Processing batch 64000 - 65000...\n",
            "Processing batch 65000 - 66000...\n",
            "Processing batch 66000 - 67000...\n",
            "Processing batch 67000 - 68000...\n",
            "Processing batch 68000 - 69000...\n",
            "Processing batch 69000 - 70000...\n",
            "Processing batch 70000 - 71000...\n",
            "Processing batch 71000 - 72000...\n",
            "Processing batch 72000 - 73000...\n",
            "Processing batch 73000 - 74000...\n",
            "Processing batch 74000 - 75000...\n",
            "Processing batch 75000 - 76000...\n",
            "Processing batch 76000 - 77000...\n",
            "Processing batch 77000 - 78000...\n",
            "Processing batch 78000 - 79000...\n",
            "Processing batch 79000 - 80000...\n",
            "Processing batch 80000 - 81000...\n",
            "Processing batch 81000 - 82000...\n",
            "Processing batch 82000 - 83000...\n",
            "Processing batch 83000 - 84000...\n",
            "Processing batch 84000 - 85000...\n",
            "Processing batch 85000 - 86000...\n",
            "Processing batch 86000 - 87000...\n",
            "Processing batch 87000 - 88000...\n",
            "Processing batch 88000 - 89000...\n",
            "Processing batch 89000 - 90000...\n",
            "Processing batch 90000 - 91000...\n",
            "Processing batch 91000 - 92000...\n",
            "Processing batch 92000 - 93000...\n",
            "Processing batch 93000 - 94000...\n",
            "Processing batch 94000 - 95000...\n",
            "Processing batch 95000 - 96000...\n",
            "Processing batch 96000 - 97000...\n",
            "Processing batch 97000 - 98000...\n",
            "Processing batch 98000 - 99000...\n",
            "Processing batch 99000 - 100000...\n",
            "Processing batch 100000 - 101000...\n",
            "Processing batch 101000 - 102000...\n",
            "Processing batch 102000 - 103000...\n",
            "Processing batch 103000 - 104000...\n",
            "Processing batch 104000 - 105000...\n",
            "Processing batch 105000 - 106000...\n",
            "Processing batch 106000 - 107000...\n",
            "Processing batch 107000 - 108000...\n",
            "Processing batch 108000 - 109000...\n",
            "Processing batch 109000 - 110000...\n",
            "Processing batch 110000 - 111000...\n",
            "Processing batch 111000 - 112000...\n",
            "Processing batch 112000 - 113000...\n",
            "Processing batch 113000 - 114000...\n",
            "Processing batch 114000 - 115000...\n",
            "Processing batch 115000 - 116000...\n",
            "Processing batch 116000 - 117000...\n",
            "Processing batch 117000 - 118000...\n",
            "Processing batch 118000 - 119000...\n",
            "Processing batch 119000 - 120000...\n",
            "Processing batch 120000 - 121000...\n",
            "Processing batch 121000 - 122000...\n",
            "Processing batch 122000 - 123000...\n",
            "Processing batch 123000 - 124000...\n",
            "Processing batch 124000 - 125000...\n",
            "Processing batch 125000 - 126000...\n",
            "Processing batch 126000 - 127000...\n",
            "Processing batch 127000 - 128000...\n",
            "Processing batch 128000 - 129000...\n",
            "Processing batch 129000 - 130000...\n",
            "Processing batch 130000 - 131000...\n",
            "Processing batch 131000 - 132000...\n",
            "Processing batch 132000 - 133000...\n",
            "Processing batch 133000 - 134000...\n",
            "Processing batch 134000 - 135000...\n",
            "Processing batch 135000 - 136000...\n",
            "Processing batch 136000 - 137000...\n",
            "Processing batch 137000 - 138000...\n",
            "Processing batch 138000 - 139000...\n",
            "Processing batch 139000 - 140000...\n",
            "Processing batch 140000 - 141000...\n",
            "Processing batch 141000 - 142000...\n",
            "Processing batch 142000 - 143000...\n",
            "Processing batch 143000 - 144000...\n",
            "Processing batch 144000 - 145000...\n",
            "Processing batch 145000 - 146000...\n",
            "Processing batch 146000 - 147000...\n",
            "Processing batch 147000 - 148000...\n",
            "Processing batch 148000 - 149000...\n",
            "Processing batch 149000 - 150000...\n",
            "Processing batch 150000 - 151000...\n",
            "Processing batch 151000 - 152000...\n",
            "Processing batch 152000 - 153000...\n",
            "Processing batch 153000 - 154000...\n",
            "Processing batch 154000 - 155000...\n",
            "Processing batch 155000 - 156000...\n",
            "Processing batch 156000 - 157000...\n",
            "Processing batch 157000 - 158000...\n",
            "Processing batch 158000 - 159000...\n",
            "Processing batch 159000 - 160000...\n",
            "Processing batch 160000 - 161000...\n",
            "Processing batch 161000 - 162000...\n",
            "Processing batch 162000 - 163000...\n",
            "Processing batch 163000 - 164000...\n",
            "Processing batch 164000 - 165000...\n",
            "Processing batch 165000 - 166000...\n",
            "Processing batch 166000 - 167000...\n",
            "Processing batch 167000 - 168000...\n",
            "Processing batch 168000 - 169000...\n",
            "Processing batch 169000 - 170000...\n",
            "Processing batch 170000 - 171000...\n",
            "Processing batch 171000 - 172000...\n",
            "Processing batch 172000 - 173000...\n",
            "Processing batch 173000 - 174000...\n",
            "Processing batch 174000 - 175000...\n",
            "Processing batch 175000 - 176000...\n",
            "Processing batch 176000 - 177000...\n",
            "Processing batch 177000 - 178000...\n",
            "Processing batch 178000 - 179000...\n",
            "Processing batch 179000 - 180000...\n",
            "Processing batch 180000 - 181000...\n",
            "Processing batch 181000 - 182000...\n",
            "Processing batch 182000 - 183000...\n",
            "Processing batch 183000 - 184000...\n",
            "Processing batch 184000 - 185000...\n",
            "Processing batch 185000 - 186000...\n",
            "Processing batch 186000 - 187000...\n",
            "Processing batch 187000 - 188000...\n",
            "Processing batch 188000 - 189000...\n",
            "Processing batch 189000 - 190000...\n",
            "Processing batch 190000 - 191000...\n",
            "Processing batch 191000 - 192000...\n",
            "Processing batch 192000 - 193000...\n",
            "Processing batch 193000 - 194000...\n",
            "Processing batch 194000 - 195000...\n",
            "Processing batch 195000 - 196000...\n",
            "Processing batch 196000 - 197000...\n",
            "Processing batch 197000 - 198000...\n",
            "Processing batch 198000 - 199000...\n",
            "Processing batch 199000 - 200000...\n",
            "Processing batch 200000 - 201000...\n",
            "Processing batch 201000 - 202000...\n",
            "Processing batch 202000 - 203000...\n",
            "Processing batch 203000 - 204000...\n",
            "Processing batch 204000 - 205000...\n",
            "Processing batch 205000 - 206000...\n",
            "Processing batch 206000 - 207000...\n",
            "Processing batch 207000 - 208000...\n",
            "Processing batch 208000 - 209000...\n",
            "Processing batch 209000 - 210000...\n",
            "Processing batch 210000 - 211000...\n",
            "Processing batch 211000 - 212000...\n",
            "Processing batch 212000 - 213000...\n",
            "Processing batch 213000 - 214000...\n",
            "Processing batch 214000 - 215000...\n",
            "Processing batch 215000 - 216000...\n",
            "Processing batch 216000 - 217000...\n",
            "Processing batch 217000 - 218000...\n",
            "Processing batch 218000 - 219000...\n",
            "Processing batch 219000 - 220000...\n",
            "Processing batch 220000 - 221000...\n",
            "Processing batch 221000 - 222000...\n",
            "Processing batch 222000 - 223000...\n",
            "Processing batch 223000 - 224000...\n",
            "Processing batch 224000 - 225000...\n",
            "Processing batch 225000 - 226000...\n",
            "Processing batch 226000 - 227000...\n",
            "Processing batch 227000 - 228000...\n",
            "Processing batch 228000 - 229000...\n",
            "Processing batch 229000 - 230000...\n",
            "Processing batch 230000 - 231000...\n",
            "Processing batch 231000 - 232000...\n",
            "Processing batch 232000 - 233000...\n",
            "Processing batch 233000 - 234000...\n",
            "Processing batch 234000 - 235000...\n",
            "Processing batch 235000 - 236000...\n",
            "Processing batch 236000 - 237000...\n",
            "Processing batch 237000 - 238000...\n",
            "Processing batch 238000 - 239000...\n",
            "Processing batch 239000 - 240000...\n",
            "Processing batch 240000 - 241000...\n",
            "Processing batch 241000 - 242000...\n",
            "Processing batch 242000 - 243000...\n",
            "Processing batch 243000 - 244000...\n",
            "Processing batch 244000 - 245000...\n",
            "Processing batch 245000 - 246000...\n",
            "Processing batch 246000 - 247000...\n",
            "Processing batch 247000 - 248000...\n",
            "Processing batch 248000 - 249000...\n",
            "Processing batch 249000 - 250000...\n",
            "Processing batch 250000 - 251000...\n",
            "Processing batch 251000 - 252000...\n",
            "Processing batch 252000 - 253000...\n",
            "Processing batch 253000 - 254000...\n",
            "Processing batch 254000 - 255000...\n",
            "Processing batch 255000 - 256000...\n",
            "Processing batch 256000 - 257000...\n",
            "Processing batch 257000 - 258000...\n",
            "Processing batch 258000 - 259000...\n",
            "Processing batch 259000 - 260000...\n",
            "Processing batch 260000 - 261000...\n",
            "Processing batch 261000 - 262000...\n",
            "Processing batch 262000 - 263000...\n",
            "Processing batch 263000 - 264000...\n",
            "Processing batch 264000 - 265000...\n",
            "Processing batch 265000 - 266000...\n",
            "Processing batch 266000 - 267000...\n",
            "Processing batch 267000 - 268000...\n",
            "Processing batch 268000 - 269000...\n",
            "Processing batch 269000 - 270000...\n",
            "Processing batch 270000 - 271000...\n",
            "Processing batch 271000 - 272000...\n",
            "Processing batch 272000 - 273000...\n",
            "Processing batch 273000 - 274000...\n",
            "Processing batch 274000 - 275000...\n",
            "Processing batch 275000 - 276000...\n",
            "Processing batch 276000 - 277000...\n",
            "Processing batch 277000 - 278000...\n",
            "Processing batch 278000 - 279000...\n",
            "Processing batch 279000 - 280000...\n",
            "Processing batch 280000 - 281000...\n",
            "Processing batch 281000 - 282000...\n",
            "Processing batch 282000 - 283000...\n",
            "Processing batch 283000 - 283208...\n",
            "Successfully tokenized dataset and saved it in batches!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load tokenized dataset\n",
        "df_tokenized = pd.read_parquet(\"/content/sepsis_notes_tokenized.parquet\")\n",
        "\n",
        "# Print basic info\n",
        "print(df_tokenized.info())\n",
        "print(df_tokenized.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlIPO03m9068",
        "outputId": "bb181f2a-ad25-4592-fce3-9444803ecda1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 283208 entries, 0 to 283207\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   HADM_ID         283208 non-null  Int64 \n",
            " 1   input_ids       283208 non-null  object\n",
            " 2   attention_mask  283208 non-null  object\n",
            " 3   sepsis          283208 non-null  int64 \n",
            "dtypes: Int64(1), int64(1), object(2)\n",
            "memory usage: 8.9+ MB\n",
            "None\n",
            "   HADM_ID                                          input_ids  \\\n",
            "0   167853  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "1   107527  [101, 10296, 2236, 131, 12398, 2236, 131, 2236...   \n",
            "2   167118  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "3   196489  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "4   135453  [101, 10296, 2236, 131, 12398, 2236, 131, 2236...   \n",
            "\n",
            "                                      attention_mask  sepsis  \n",
            "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp /content/sepsis_notes_tokenized.parquet gs://mimic3-dataset/MIMIC-III/\n",
        "\n",
        "print(\"Tokenized dataset successfully uploaded to GCS!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-egMzgR95mu",
        "outputId": "b98aee6b-1f52-4aa1-d018-27f527f72591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file:///content/sepsis_notes_tokenized.parquet [Content-Type=application/octet-stream]...\n",
            "/ [0 files][    0.0 B/166.9 MiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "\\\n",
            "Operation completed over 1 objects/166.9 MiB.                                    \n",
            "Tokenized dataset successfully uploaded to GCS!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training BioClinicalBERT**"
      ],
      "metadata": {
        "id": "ymPjxOsA-RuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load tokenized data from Google Cloud Storage (GCS)"
      ],
      "metadata": {
        "id": "OdhfmnRF-sbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jT-ED6jIa0k",
        "outputId": "e502ae60-3cdd-4322-deb7-6d9d9fdb2441"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the GCS path\n",
        "#gcs_path = \"https://drive.google.com/file/d/1gVzuNiiQs-r6vDQvj_OS7luZy-lVIFvF/view?usp=drive_link\"\n",
        "\n",
        "# Load tokenized dataset\n",
        "df = pd.read_parquet('/content/drive/MyDrive/MIMIC-III_sepsis_notes_tokenized.parquet')\n",
        "\n",
        "# Show dataset structure\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouyd5Cog-TiR",
        "outputId": "00363358-8e9b-4337-f347-c4a22d72590a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 283208 entries, 0 to 283207\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   HADM_ID         283208 non-null  Int64 \n",
            " 1   input_ids       283208 non-null  object\n",
            " 2   attention_mask  283208 non-null  object\n",
            " 3   sepsis          283208 non-null  int64 \n",
            "dtypes: Int64(1), int64(1), object(2)\n",
            "memory usage: 8.9+ MB\n",
            "None\n",
            "   HADM_ID                                          input_ids  \\\n",
            "0   167853  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "1   107527  [101, 10296, 2236, 131, 12398, 2236, 131, 2236...   \n",
            "2   167118  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "3   196489  [101, 10296, 2236, 131, 12398, 2236, 131, 1555...   \n",
            "4   135453  [101, 10296, 2236, 131, 12398, 2236, 131, 2236...   \n",
            "\n",
            "                                      attention_mask  sepsis  \n",
            "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n",
            "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to Tensor Dataset: We now create PyTorch tensors that will be used for training. Convert Data for PyTorch\n",
        "\n",
        "Since input_ids and attention_mask are stored as lists in object columns, we need to convert them to tensors."
      ],
      "metadata": {
        "id": "WxLvYdvei_y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SepsisDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        # Convert lists of tokens to PyTorch tensors efficiently\n",
        "        self.input_ids = torch.tensor(np.array(dataframe[\"input_ids\"].tolist()), dtype=torch.long)\n",
        "        self.attention_mask = torch.tensor(np.array(dataframe[\"attention_mask\"].tolist()), dtype=torch.long)\n",
        "        self.labels = torch.tensor(dataframe[\"sepsis\"].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.input_ids[idx],\n",
        "            \"attention_mask\": self.attention_mask[idx],\n",
        "            \"labels\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create dataset\n",
        "dataset = SepsisDataset(df)\n",
        "\n",
        "# Split into train & validation sets (80/20 split)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f\"Train samples: {len(train_set)}, Validation samples: {len(val_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-vHVCno-2LG",
        "outputId": "9da4f1fa-dc6b-430a-87b1-eb7818446091"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 226566, Validation samples: 56642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we load BioClinicalBERT & define our model:"
      ],
      "metadata": {
        "id": "Djx8wxHE--AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load model & tokenizer\n",
        "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "352700c94d174f11a2b96625372aa61e",
            "aa28cb2849d34f29b7e741fd8854c774",
            "ce15ec86c5f644dd91eaa7024b0accef",
            "99520750ea474fbbb40cff79050d4070",
            "730e8eaae1dd4e5aa953af5414766eff",
            "0c9def4c2a264874a95f26f7754bd7b5",
            "52358db6bb144c1da5db7381a6ff81f0",
            "4fe5cb126ac44db39e7fe2822a7c4e85",
            "52643507b4dd4a68abfce1fe279ff622",
            "e35df0584cf5428daac7977145829bc2",
            "d5d57d41b3314213b8f5c49d382cf121",
            "73b5aec6c3254836aff7aacb7b8a909f",
            "a709589a1c0a4c5d8a8a2bfb479189e0",
            "0adc4aab0d2d48bd97a1fa1fdc9bc9ad",
            "953f7e45026f425d8c38bed3b23dd8b8",
            "8cad5a6953334cc6b0c27e89f5e87b05",
            "4b369b2e6b254e28a9c12e70322eca45",
            "55df2394ab34409c81531a5be6afc7b0",
            "79ca25eeb6b24e8e976c91104f86360f",
            "e7003f8cb1644e10893b9acaa6cc3211",
            "3712ed1c8f164c94abb2aad77c62723c",
            "aeaa4a1f98b747cfb625ff01f0eda3a4",
            "3e5f144e8343415a9187139087fd025e",
            "aaa66dab711540e7812b4ea625e1a5a3",
            "05523a28e04b4a1a9c68f570c0a00a2b",
            "8b73f8c4144047b49aedaf5254b566c6",
            "5f4e5bc0c558437aa0ccbca33f4b6712",
            "fc034183bf0d4850868aef8d6725e224",
            "29891a16f6dc490f8d1896c46de77215",
            "3aee4a0186374b6596a4b0b93edd9ba8",
            "57e869be6d6c4de0b600325c493f5b70",
            "21f96b3f5dc84b3ab232a007b3f7c42a",
            "69aaa4c61c9c4ea5afaed569f185fe1d"
          ]
        },
        "id": "QG4Y0fiu_FT9",
        "outputId": "d670393a-6d64-4836-a67e-b8c9a48a1c05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "352700c94d174f11a2b96625372aa61e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73b5aec6c3254836aff7aacb7b8a909f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e5f144e8343415a9187139087fd025e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Training: we define\n",
        "- Loss function: CrossEntropyLoss\n",
        "- Optimizer: AdamW\n",
        "- Evaluation metric: Accuracy, Precision, Recall, F1-score"
      ],
      "metadata": {
        "id": "9Qf2JSPH_IwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Set up training parameters (Disable W&B)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,  # Reduce if crashing\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=2,\n",
        "    fp16=True,  # Mixed precision for efficiency\n",
        "    report_to=\"none\"  # Disables Weights & Biases (W&B)\n",
        ")\n",
        "\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set\n",
        ")\n",
        "\n",
        "print(\"Training setup optimized & ready to start!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kY0_mKz_La7",
        "outputId": "af26c704-ec68-42cf-b246-1a5f9a2e1bea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training setup optimized & ready to start!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the Model**"
      ],
      "metadata": {
        "id": "3eIDX4qIB1Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "VwRQYDQsB4kW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "2f2c7847-ddd9-4db7-a789-3550199e5c39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='84963' max='84963' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [84963/84963 1:16:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.543300</td>\n",
              "      <td>0.542276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.528100</td>\n",
              "      <td>0.532399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.550800</td>\n",
              "      <td>0.532280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=84963, training_loss=0.5397352676119518, metrics={'train_runtime': 4617.2114, 'train_samples_per_second': 147.21, 'train_steps_per_second': 18.401, 'total_flos': 1.7883605810608128e+17, 'train_loss': 0.5397352676119518, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating Model Performance**"
      ],
      "metadata": {
        "id": "JYprA3rkB69L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Get predictions\n",
        "predictions = trainer.predict(val_set)\n",
        "pred_labels = predictions.predictions.argmax(axis=1)\n",
        "\n",
        "# Extract true labels\n",
        "true_labels = [example[\"labels\"].item() for example in val_set]\n",
        "\n",
        "# Compute accuracy, precision, recall, F1-score\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average=\"binary\")\n",
        "\n",
        "print(f\" Model Performance:\")\n",
        "print(f\" Accuracy: {accuracy:.4f}\")\n",
        "print(f\" Precision: {precision:.4f}\")\n",
        "print(f\" Recall: {recall:.4f}\")\n",
        "print(f\" F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "AmWj_FUoB_Df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "48727f8c-c791-468e-9da2-d864452c2da8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model Performance:\n",
            " Accuracy: 0.7757\n",
            " Precision: 0.0000\n",
            " Recall: 0.0000\n",
            " F1-score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}